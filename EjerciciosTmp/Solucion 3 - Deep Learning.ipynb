{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solucion 3 - Deep Learning\n",
    "\n",
    "Con esta solución queremos probar solamente que tan bien se ajustan algunos modelos de redes neuronales utilizando el estado del arte en deep learning utilizando TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos librerías a usar y los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import tensorflow as tf\n",
    "# from tensorflow.contrib.tensor_forest.python import tensor_forest\n",
    "# Ignoramos todos los GPUs, debido a que tf random forest no se beneficia de ello.\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "# !export TF_CPP_MIN_LOG_LEVEL=2\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "# plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de observaciones 1074992 con 122 variables: \n",
      "Cantidad de observaciones 1074992 con 41 variables (Entrenamiento) \n",
      "Cantidad de observaciones 311029 con 41 variables (Validación) \n",
      "Balanceo de datos: \n",
      "normal    200000\n",
      "dos       100000\n",
      "probe      13860\n",
      "r2l          999\n",
      "u2r           52\n",
      "Name: attack_category, dtype: int64\n",
      "dos       223298\n",
      "normal     60593\n",
      "r2l         5993\n",
      "probe       2377\n",
      "u2r           39\n",
      "Name: attack_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos completos para seleccionar mas variables\n",
    "ataques_train = pd.read_csv('data/kddcup.data_clean.csv', sep=',', decimal='.')\n",
    "print(\"Cantidad de observaciones %i con %i variables: \" %(ataques_train.shape[0],ataques_train.shape[1]))\n",
    "feature_cols = ['same_srv_rate', 'flag_SF', 'dst_host_same_srv_rate', 'service_private',\n",
    "       'dst_host_srv_serror_rate', 'service_http', 'logged_in',\n",
    "       'dst_host_srv_count', 'count', 'srv_serror_rate', 'flag_S0',\n",
    "       'dst_host_serror_rate', 'dst_host_count', 'rerror_rate', 'serror_rate',\n",
    "       'dst_host_rerror_rate', 'src_bytes', 'srv_rerror_rate',\n",
    "       'dst_host_same_src_port_rate', 'dst_host_srv_rerror_rate',\n",
    "       'protocol_type_udp', 'service_ecr_i', 'flag_REJ', 'service_pop_3',\n",
    "       'protocol_type_tcp', 'diff_srv_rate', 'hot', 'dst_host_diff_srv_rate',\n",
    "       'service_telnet', 'service_domain_u', 'wrong_fragment',\n",
    "       'dst_host_srv_diff_host_rate', 'num_compromised', 'service_smtp',\n",
    "       'srv_count', 'dst_bytes', 'srv_diff_host_rate', 'service_ftp_data',\n",
    "       'duration', 'service_ftp', 'attack_category']\n",
    "\n",
    "ataques_train = ataques_train[feature_cols]\n",
    "# Cargamos los datos de validación del 10% de la competencia \n",
    "ataques_10prec_test = pd.read_csv('data/data_10per_test_preprocessed.csv', sep=',', decimal='.')\n",
    "ataques_test = ataques_10prec_test[feature_cols]\n",
    "\n",
    "print(\"Cantidad de observaciones %i con %i variables (Entrenamiento) \" %(ataques_train.shape[0],ataques_train.shape[1]))\n",
    "print(\"Cantidad de observaciones %i con %i variables (Validación) \" %(ataques_test.shape[0],ataques_test.shape[1]))\n",
    "\n",
    "# Balanceamos los datos\n",
    "df_normal = ataques_train[ataques_train.attack_category=='normal']\n",
    "df_dos = ataques_train[ataques_train.attack_category=='dos']\n",
    "df_probe = ataques_train[ataques_train.attack_category=='probe']\n",
    "df_r2l = ataques_train[ataques_train.attack_category=='r2l']\n",
    "df_u2r = ataques_train[ataques_train.attack_category=='u2r']\n",
    "#df_unknown = ataques_train[ataques_train.attack_category=='unknown']\n",
    "\n",
    "# Remuestreo tomando solo un conjnto de datos menor en las clases de mayor frecuencia\n",
    "df_normal_downsampled = resample(df_normal, replace=False, n_samples=200000, random_state=123)\n",
    "df_dos_downsampled = resample(df_dos, replace=False, n_samples=100000, random_state=123)\n",
    "# Combinar las clases con los nuevos datos remuestreados\n",
    "ataques_train = pd.concat([df_normal_downsampled, df_dos_downsampled, df_probe, df_r2l, df_u2r])\n",
    "\n",
    "# Eliminamos los datos \"unknown\" de la muestra de validación, los cuales no tenemos como entrenar\n",
    "ataques_test = ataques_test[ataques_test.attack_category!='unknown']\n",
    "\n",
    "# Mostrar las cantidades de los nuevos datos\n",
    "print(\"Balanceo de datos: \")\n",
    "print(ataques_train.attack_category.value_counts())\n",
    "print(ataques_test.attack_category.value_counts())\n",
    "\n",
    "# Para trabajar con Tensorflow la mayoria de procesos o algoritmos requieren que las etiquetas a predecir sean numericas \n",
    "# Como se requiere que sean numericas las variables para ser computadas procedemos con\n",
    "# ataques_train[\"attack_category\"] = pd.factorize(ataques_train[\"attack_category\"])\n",
    "ataques_train[\"attack_category\"] = ataques_train[\"attack_category\"].map({\"normal\":0,\"dos\":1,\"probe\":2, \"r2l\":3, \"u2r\":4})\n",
    "ataques_test[\"attack_category\"] = ataques_test[\"attack_category\"].map({\"normal\":0,\"dos\":1,\"probe\":2, \"r2l\":3, \"u2r\":4})\n",
    "\n",
    "# Definimos los datos en entrenamiento y validación\n",
    "X = ataques_train.drop(['attack_category'], axis=1)\n",
    "y = ataques_train.attack_category.copy()\n",
    "X_test_40var = ataques_test.drop(['attack_category'], axis=1)\n",
    "y_test_40var = ataques_test.attack_category.copy()\n",
    "\n",
    "# Definimos un dataset de entrenamiento y pruebas\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Flow\n",
    "\n",
    "\n",
    "Construct, fit and evaluate the classifier\n",
    "\n",
    "DNNClassifier expects following arguments :\n",
    "\n",
    "    feature_columns : Feature columns map the data to the model. We can either use raw features from the training dataset or any derived features from them. See here for more information.\n",
    "\n",
    "    hidden_units : List containing number of hidden units in each layer. All layers would be fully connected.\n",
    "\n",
    "    n_classes : Number of classes\n",
    "\n",
    "Optionally we can also set the optimizer, dropout and activation functions. Default activation function is ReLu. If we set a model directory then it'd save the model graph, parameters etc. See the documentation for reading up on DNNClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['same_srv_rate',\n",
       " 'flag_SF',\n",
       " 'dst_host_same_srv_rate',\n",
       " 'service_private',\n",
       " 'dst_host_srv_serror_rate',\n",
       " 'service_http',\n",
       " 'logged_in',\n",
       " 'dst_host_srv_count',\n",
       " 'count',\n",
       " 'srv_serror_rate',\n",
       " 'flag_S0',\n",
       " 'dst_host_serror_rate',\n",
       " 'dst_host_count',\n",
       " 'rerror_rate',\n",
       " 'serror_rate',\n",
       " 'dst_host_rerror_rate',\n",
       " 'src_bytes',\n",
       " 'srv_rerror_rate',\n",
       " 'dst_host_same_src_port_rate',\n",
       " 'dst_host_srv_rerror_rate',\n",
       " 'protocol_type_udp',\n",
       " 'service_ecr_i',\n",
       " 'flag_REJ',\n",
       " 'service_pop_3',\n",
       " 'protocol_type_tcp',\n",
       " 'diff_srv_rate',\n",
       " 'hot',\n",
       " 'dst_host_diff_srv_rate',\n",
       " 'service_telnet',\n",
       " 'service_domain_u',\n",
       " 'wrong_fragment',\n",
       " 'dst_host_srv_diff_host_rate',\n",
       " 'num_compromised',\n",
       " 'service_smtp',\n",
       " 'srv_count',\n",
       " 'dst_bytes',\n",
       " 'srv_diff_host_rate',\n",
       " 'service_ftp_data',\n",
       " 'duration',\n",
       " 'service_ftp']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = X_train.columns.tolist()\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the Feature Columns\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "X_test_40var = X_test_40var.astype(np.float32)\n",
    "# All of the features in our training dataset are real valued and continuous.\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(k) for k in columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make input function\n",
    "def input_fn(df,labels):\n",
    "    feature_cols = {k:tf.constant(df[k].values,shape = [df[k].size,1]) for k in columns}\n",
    "    label = tf.constant(labels.values, shape = [labels.size,1])\n",
    "    return feature_cols,label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the Classifer\n",
    "\n",
    "Here the DNNClassifier is constructed with the feature_columns where the number of hidden units in each layer is 40,20,40 respectively. The number of classes is also specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/gn/6xmfkgxd30jggx1gdklnnk080000gn/T/tmp_0g93v1i\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x12051afd0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/var/folders/gn/6xmfkgxd30jggx1gdklnnk080000gn/T/tmp_0g93v1i'}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,hidden_units=[40,20,40],n_classes = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the classifier\n",
    "\n",
    "We pass the *input_fn* into the fit method and set the number of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/gn/6xmfkgxd30jggx1gdklnnk080000gn/T/tmp_0g93v1i/model.ckpt.\n",
      "INFO:tensorflow:loss = 3850.36, step = 1\n",
      "INFO:tensorflow:global_step/sec: 2.24076\n",
      "INFO:tensorflow:loss = 0.350254, step = 101 (44.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.23914\n",
      "INFO:tensorflow:loss = 0.14062, step = 201 (44.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.28229\n",
      "INFO:tensorflow:loss = 0.108211, step = 301 (43.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.28687\n",
      "INFO:tensorflow:loss = 0.126694, step = 401 (43.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.29578\n",
      "INFO:tensorflow:loss = 0.105622, step = 501 (43.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.31451\n",
      "INFO:tensorflow:loss = 0.0955609, step = 601 (43.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.26322\n",
      "INFO:tensorflow:loss = 0.0892744, step = 701 (44.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.27005\n",
      "INFO:tensorflow:loss = 0.0849647, step = 801 (44.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.30995\n",
      "INFO:tensorflow:loss = 0.0862136, step = 901 (43.291 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/gn/6xmfkgxd30jggx1gdklnnk080000gn/T/tmp_0g93v1i/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0795847.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x12051aa20>, 'hidden_units': [40, 20, 40], 'feature_columns': (_RealValuedColumn(column_name='same_srv_rate', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='flag_SF', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='dst_host_same_srv_rate', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='service_private', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='dst_host_srv_serror_rate', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='service_http', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='logged_in', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='dst_host_srv_count', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='count', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='srv_serror_rate', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='flag_S0', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='dst_host_serror_rate', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='dst_host_count', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='rerror_rate', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='serror_rate', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='dst_host_rerror_rate', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='src_bytes', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='srv_rerror_rate', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='dst_host_same_src_port_rate', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='dst_host_srv_rerror_rate', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='protocol_type_udp', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='service_ecr_i', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='flag_REJ', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='service_pop_3', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='protocol_type_tcp', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='diff_srv_rate', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='hot', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='dst_host_diff_srv_rate', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='service_telnet', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='service_domain_u', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='wrong_fragment', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='dst_host_srv_diff_host_rate', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='num_compromised', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='service_smtp', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='srv_count', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='dst_bytes', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='srv_diff_host_rate', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='service_ftp_data', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='duration', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='service_ftp', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)), 'optimizer': None, 'activation_fn': <function relu at 0x11bd26a60>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(input_fn=lambda: input_fn(X_train,y_train),steps = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Classifier\n",
    "\n",
    "Evaluate method returns some statistics like accuracy, auc after being called on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-11-28-00:50:38\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/gn/6xmfkgxd30jggx1gdklnnk080000gn/T/tmp_0g93v1i/model.ckpt-1000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-28-00:50:39\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.978582, global_step = 1000, loss = 0.0839374\n"
     ]
    }
   ],
   "source": [
    "ev = classifier.evaluate(input_fn=lambda: input_fn(X_test,y_test),steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.083937362, 'accuracy': 0.97858155, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "print(ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_predict(df):\n",
    "    feature_cols = {k:tf.constant(df[k].values,shape = [df[k].size,1]) for k in columns}\n",
    "    return feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/gn/6xmfkgxd30jggx1gdklnnk080000gn/T/tmp_0g93v1i/model.ckpt-1000\n"
     ]
    }
   ],
   "source": [
    "pred = classifier.predict_classes(input_fn=lambda: input_predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object DNNClassifier.predict_classes.<locals>.<genexpr> at 0x157b48938>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred\n",
    "#print(list(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/gn/6xmfkgxd30jggx1gdklnnk080000gn/T/tmp_0g93v1i/model.ckpt-1000\n",
      "Precisión NN: 94.84%\n",
      "[[ 59620   7541    190   5979     39]\n",
      " [   802 215734    334      1      0]\n",
      " [   171     23   1853     13      0]\n",
      " [     0      0      0      0      0]\n",
      " [     0      0      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "pred_class = classifier.predict_classes(input_fn=lambda: input_predict(X_test_40var))\n",
    "\n",
    "y_pred = list(pred_class)\n",
    "precision = accuracy_score(y_pred, y_test_40var)\n",
    "print(\"Precisión NN: %.2f%%\" %(precision*100))\n",
    "conf_mat = confusion_matrix(y_pred, y_test_40var)\n",
    "print(conf_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que tiene una precisión aceptable pero no modela bien las clases con frecuencia baja, a pesar de que los datos han sido balanceados con aterioridad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gisenv)",
   "language": "python",
   "name": "gisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
