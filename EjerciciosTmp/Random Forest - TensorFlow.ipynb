{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest usando TensorFlow\n",
    "\n",
    "Implementación del algoritmo Random Forest utilizando la librería TensorFlow, aplicandolo a la clasificación de intrusos en redes. La base de datos puede ser consultada en ()\n",
    "\n",
    "- Author: Ernesto Giron E."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensor_forest.python import tensor_forest\n",
    "# Ignoramos todos los GPUs, debido a que tf random forest no se beneficia de ello.\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "# !export TF_CPP_MIN_LOG_LEVEL=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de observaciones 1074992 con 122 variables: \n",
      "Cantidad de observaciones 1074992 con 41 variables (Entrenamiento) \n",
      "Cantidad de observaciones 311029 con 41 variables (Validación) \n",
      "Balanceo de datos: \n",
      "normal    200000\n",
      "dos       100000\n",
      "probe      13860\n",
      "r2l          999\n",
      "u2r           52\n",
      "Name: attack_category, dtype: int64\n",
      "dos       223298\n",
      "normal     60593\n",
      "r2l         5993\n",
      "probe       2377\n",
      "u2r           39\n",
      "Name: attack_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos y seleccionamos algunas variables importantes\n",
    "ataques_train = pd.read_csv('data/kddcup.data_clean.csv', sep=',', decimal='.')\n",
    "print(\"Cantidad de observaciones %i con %i variables: \" %(ataques_train.shape[0],ataques_train.shape[1]))\n",
    "feature_cols = ['same_srv_rate', 'flag_SF', 'dst_host_same_srv_rate', 'service_private',\n",
    "       'dst_host_srv_serror_rate', 'service_http', 'logged_in',\n",
    "       'dst_host_srv_count', 'count', 'srv_serror_rate', 'flag_S0',\n",
    "       'dst_host_serror_rate', 'dst_host_count', 'rerror_rate', 'serror_rate',\n",
    "       'dst_host_rerror_rate', 'src_bytes', 'srv_rerror_rate',\n",
    "       'dst_host_same_src_port_rate', 'dst_host_srv_rerror_rate',\n",
    "       'protocol_type_udp', 'service_ecr_i', 'flag_REJ', 'service_pop_3',\n",
    "       'protocol_type_tcp', 'diff_srv_rate', 'hot', 'dst_host_diff_srv_rate',\n",
    "       'service_telnet', 'service_domain_u', 'wrong_fragment',\n",
    "       'dst_host_srv_diff_host_rate', 'num_compromised', 'service_smtp',\n",
    "       'srv_count', 'dst_bytes', 'srv_diff_host_rate', 'service_ftp_data',\n",
    "       'duration', 'service_ftp', 'attack_category']\n",
    "\n",
    "ataques_train = ataques_train[feature_cols]\n",
    "# Cargamos los datos de validación del 10% de la competencia \n",
    "ataques_10prec_test = pd.read_csv('data/data_10per_test_preprocessed.csv', sep=',', decimal='.')\n",
    "ataques_test = ataques_10prec_test[feature_cols]\n",
    "\n",
    "print(\"Cantidad de observaciones %i con %i variables (Entrenamiento) \" %(ataques_train.shape[0],ataques_train.shape[1]))\n",
    "print(\"Cantidad de observaciones %i con %i variables (Validación) \" %(ataques_test.shape[0],ataques_test.shape[1]))\n",
    "\n",
    "# Balanceamos los datos\n",
    "df_normal = ataques_train[ataques_train.attack_category=='normal']\n",
    "df_dos = ataques_train[ataques_train.attack_category=='dos']\n",
    "df_probe = ataques_train[ataques_train.attack_category=='probe']\n",
    "df_r2l = ataques_train[ataques_train.attack_category=='r2l']\n",
    "df_u2r = ataques_train[ataques_train.attack_category=='u2r']\n",
    "#df_unknown = ataques_train[ataques_train.attack_category=='unknown']\n",
    "\n",
    "# Remuestreo tomando solo un conjnto de datos menor en las clases de mayor frecuencia\n",
    "df_normal_downsampled = resample(df_normal, replace=False, n_samples=200000, random_state=123)\n",
    "df_dos_downsampled = resample(df_dos, replace=False, n_samples=100000, random_state=123)\n",
    "# Combinar las clases con los nuevos datos remuestreados\n",
    "ataques_train = pd.concat([df_normal_downsampled, df_dos_downsampled, df_probe, df_r2l, df_u2r])\n",
    "\n",
    "# Eliminamos los datos \"unknown\" de la muestra de validación, los cuales no tenemos como entrenar\n",
    "ataques_test = ataques_test[ataques_test.attack_category!='unknown']\n",
    "\n",
    "# Mostrar las cantidades de los nuevos datos\n",
    "print(\"Balanceo de datos: \")\n",
    "print(ataques_train.attack_category.value_counts())\n",
    "print(ataques_test.attack_category.value_counts())\n",
    "\n",
    "# Definimos los datos en entrenamiento y validación\n",
    "X = ataques_train.drop(['attack_category'], axis=1)\n",
    "y = ataques_train.attack_category.copy()\n",
    "X_test_40var = ataques_test.drop(['attack_category'], axis=1)\n",
    "y_test_40var = ataques_test.attack_category.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=35)\n",
    "\n",
    "# y_train debe ser númerico y entero para usar con RF\n",
    "y_train_int = pd.factorize(y_train)\n",
    "y_test_int = pd.factorize(y_test)\n",
    "y_test_40var_int = pd.factorize(y_test_40var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parámetros del modelo\n",
    "num_steps = 2000 # Número de pasos para entrenar\n",
    "batch_size = 200 # Número de observaciones por lote\n",
    "num_classes = len(y.unique().tolist()) # Los 5 categorias de tipos de ataques\n",
    "num_features = X.shape[1] # Cantidad de atributos (40)\n",
    "num_trees = 5  # Cantidad de árboles a sembrar\n",
    "max_nodes = 50 # Cantidad de máxima de nodos\n",
    "\n",
    "# Definimos X e Y para los datos de entrada y salida\n",
    "X_ = tf.placeholder(tf.float32, shape=[None, num_features]) # None para luego agregar cuanta observación queramos\n",
    "# Para random forest, las etiquetas deben ser de tipo entero (la clase id)\n",
    "Y_ = tf.placeholder(tf.int32, shape=[None]) # Igual None por que depende del número de observaciones que tengamos\n",
    "\n",
    "# Random Forest Parámetros\n",
    "hparams = tensor_forest.ForestHParams(num_classes=num_classes,\n",
    "                                      num_features=num_features,\n",
    "                                      num_trees=num_trees,\n",
    "                                      max_nodes=max_nodes).fill()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Constructing forest with params = \n",
      "INFO:tensorflow:{'num_trees': 5, 'max_nodes': 50, 'bagging_fraction': 1.0, 'feature_bagging_fraction': 1.0, 'num_splits_to_consider': 40, 'max_fertile_nodes': 25, 'split_after_samples': 250, 'min_split_samples': 5, 'valid_leaf_threshold': 1, 'dominate_method': 'bootstrap', 'dominate_fraction': 0.99, 'num_classes': 5, 'num_features': 40, 'bagged_num_features': 40, 'bagged_features': None, 'regression': False, 'num_outputs': 1, 'num_output_columns': 6, 'split_initializations_per_input': 1, 'base_random_seed': 0}\n",
      "INFO:tensorflow:training graph for tree: 0\n",
      "INFO:tensorflow:training graph for tree: 1\n",
      "INFO:tensorflow:training graph for tree: 2\n",
      "INFO:tensorflow:training graph for tree: 3\n",
      "INFO:tensorflow:training graph for tree: 4\n"
     ]
    }
   ],
   "source": [
    "# Construimos nuestro modelo con Random Forest\n",
    "# tf.reset_default_graph()\n",
    "forest_graph = tensor_forest.RandomForestGraphs(hparams)\n",
    "# Obtenemos los gráfos de entrenamiento y perdida\n",
    "train_op = forest_graph.training_graph(X_, Y_)\n",
    "loss_op = forest_graph.training_loss(X_, Y_)\n",
    "\n",
    "# Medimos la precisión de nuestro modelo\n",
    "infer_op = forest_graph.inference_graph(X_)\n",
    "correct_prediction = tf.equal(tf.argmax(infer_op, 1), tf.cast(Y_, tf.int64))\n",
    "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Inicializamos las variables a usar\n",
    "init_vars = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels, isDataFrame=True):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    if (isDataFrame):\n",
    "        data_shuffle = [data.iloc[i] for i in idx]\n",
    "        labels_shuffle = [labels[i] for i in idx]\n",
    "    else:\n",
    "        data_shuffle = [data[i] for i in idx]\n",
    "        labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 1, Costo: -0.000000, Precisión: 0.670000\n",
      "Paso 50, Costo: -44.400002, Precisión: 0.955000\n",
      "Paso 100, Costo: -48.000000, Precisión: 0.980000\n",
      "Paso 150, Costo: -48.000000, Precisión: 0.985000\n",
      "Paso 200, Costo: -48.000000, Precisión: 0.990000\n",
      "Paso 250, Costo: -48.000000, Precisión: 0.975000\n",
      "Paso 300, Costo: -48.000000, Precisión: 0.985000\n",
      "Paso 350, Costo: -48.000000, Precisión: 0.970000\n",
      "Paso 400, Costo: -48.000000, Precisión: 0.980000\n",
      "Paso 450, Costo: -48.000000, Precisión: 0.980000\n",
      "Paso 500, Costo: -48.000000, Precisión: 0.975000\n",
      "Paso 550, Costo: -48.000000, Precisión: 0.985000\n",
      "Paso 600, Costo: -48.000000, Precisión: 0.970000\n",
      "Paso 650, Costo: -48.000000, Precisión: 0.980000\n",
      "Paso 700, Costo: -48.000000, Precisión: 0.985000\n",
      "Paso 750, Costo: -48.000000, Precisión: 0.990000\n",
      "Paso 800, Costo: -48.000000, Precisión: 0.960000\n",
      "Paso 850, Costo: -48.000000, Precisión: 0.990000\n",
      "Paso 900, Costo: -48.000000, Precisión: 0.965000\n",
      "Paso 950, Costo: -48.000000, Precisión: 0.995000\n",
      "Paso 1000, Costo: -48.000000, Precisión: 0.970000\n",
      "Paso 1050, Costo: -48.000000, Precisión: 0.985000\n",
      "Paso 1100, Costo: -48.000000, Precisión: 0.985000\n",
      "Paso 1150, Costo: -48.000000, Precisión: 0.985000\n",
      "Paso 1200, Costo: -48.000000, Precisión: 0.955000\n",
      "Paso 1250, Costo: -48.000000, Precisión: 0.990000\n",
      "Paso 1300, Costo: -48.000000, Precisión: 0.975000\n",
      "Paso 1350, Costo: -48.000000, Precisión: 0.985000\n",
      "Paso 1400, Costo: -48.000000, Precisión: 0.975000\n",
      "Paso 1450, Costo: -48.000000, Precisión: 0.985000\n",
      "Paso 1500, Costo: -48.000000, Precisión: 0.980000\n",
      "Paso 1550, Costo: -48.000000, Precisión: 0.985000\n",
      "Paso 1600, Costo: -48.000000, Precisión: 0.975000\n",
      "Paso 1650, Costo: -48.000000, Precisión: 0.975000\n",
      "Paso 1700, Costo: -48.000000, Precisión: 0.995000\n",
      "Paso 1750, Costo: -48.000000, Precisión: 0.965000\n",
      "Paso 1800, Costo: -48.000000, Precisión: 0.975000\n",
      "Paso 1850, Costo: -48.000000, Precisión: 0.985000\n",
      "Paso 1900, Costo: -48.000000, Precisión: 0.995000\n",
      "Paso 1950, Costo: -48.000000, Precisión: 0.980000\n",
      "Paso 2000, Costo: -48.000000, Precisión: 0.990000\n"
     ]
    }
   ],
   "source": [
    "# Iniciamos una sesión de TensorFlow\n",
    "sess = tf.Session()\n",
    "\n",
    "# Ejecutamos el inicializador de variables\n",
    "sess.run(init_vars)\n",
    "\n",
    "# Entrenamos nuestro modelo\n",
    "for i in range(1, num_steps + 1):\n",
    "    # Preparamos los datos\n",
    "    batch_x, batch_y = next_batch(batch_size, X_train, y_train_int[0])\n",
    "    _, l = sess.run([train_op, loss_op], feed_dict={X_: batch_x, Y_: batch_y})\n",
    "    if i % 50 == 0 or i == 1:\n",
    "        acc = sess.run(accuracy_op, feed_dict={X_: batch_x, Y_: batch_y})\n",
    "        print('Paso %i, Costo: %f, Precisión: %f' % (i, l, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión :  0.0109236\n",
      "Precisión TF Random Forest:  0.770103\n"
     ]
    }
   ],
   "source": [
    "# Validar el Modelo\n",
    "print(\"Precisión : \", sess.run(accuracy_op, feed_dict={X_: X_test, Y_: y_test_int[0]}))\n",
    "\n",
    "# Validar el Modelo con los datos del concurso\n",
    "print(\"Precisión TF Random Forest: \", sess.run(accuracy_op, feed_dict={X_: X_test_40var, Y_: y_test_40var_int[0]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gisenv)",
   "language": "python",
   "name": "gisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
