{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solucion # 2\n",
    "\n",
    "Autor: Ernesto Girón E. \n",
    "\n",
    "## Detección de intrusos en redes\n",
    "\n",
    "Estos datos fueron usados para la edición de 1999 del KDD cup. Los datos fueron generados por Lincoln Labs: _Nueve semanas de registro de paquetes TCP fueron recolectadas para una red LAN de una oficina de las fuerzas aéreas de USA._ Durante el uso de la LAN, _varios ataques_ fueron ejecutados por el personal. El paquete crudo fue agregado junto con la información de la conexión. \n",
    "\n",
    "Para cada registro, algunas características extra fueron derivadas, basados en conocimiento del dominio sobre ataques a redes; _hay 38 tipos diferentes de ataques, pertenecientes a 4 categorías principales_. Algunos tipos de ataque aparecen solo en los datos de prueba(test data), y las frecuencias de los tipo de ataque en los conjuntos de entrenamiento y prueba no son las mismas(para hacerlo más realista). Información adicional sobre los datos puede ser encontrada en (http://kdd.ics.uci.edu/databases/kddcup99/task.html) y los resumenes de los resultados de la competencia KDD cup (http://cseweb.ucsd.edu/~elkan/clresults.html). En la última página también se indica que hay una matriz de costo asociada con las equivocaciones.  El ganador de la competencia usó árboles de decisión C5 en combinación con boosting y bagging.\n",
    "\n",
    "**Referencias**:\n",
    "- PNrule: _A New Framework for Learning Classifier Models in Data Mining (A Case-Study in Network Intrusion Detection) (2000) by R. Agarwal and M. V. Joshi_. This paper proposes a new, very simple rule learning algorithm, and tests it on the network intrusion dataset. In the first stage, rules are learned to identify the target class, and then in the second stage, rules are learned to identify cases that were incorrectly classified as positive according to the first rules.\n",
    "\n",
    "## Pasos a llevar a cabo en la solución 2\n",
    "\n",
    "- Cargar las librerías a utilizar\n",
    "- Cargar los datos completos ya procesados a un dataframe\n",
    "- Visualización rápida de los datos\n",
    "- Separando el conjunto de datos de entrenamiento y de validación\n",
    "- Selección de algoritmos y métodos usados en la Solución 1\n",
    "- Resumen de los métodos utilizados\n",
    "- Comparación de resultados con el ganador del KDDCup\n",
    "\n",
    "En este notebook solo nos dedicaremos a la implementación de algoritmos, modelos y métodos utilizando el juego de datos completo y depurado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar las librerías a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score, make_scorer, accuracy_score, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Modulo personal para hacer mas claro el ejercicio\n",
    "from egironML import EDA\n",
    "from egironML import run_kfold\n",
    "\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar los datos\n",
    "\n",
    "Los datos que se cargan a continuación ya fueron procesados para ser utilizados eficientemente en los diferentes algoritmos y/o programas de ML. Los pasos que se llevaron a cabo pueden ser vistos en [Solución 2 - Depurar-dataset-completo](Solucion%202%20-%20Depurar%20dataset%20completo.ipynb#Solucion-2---Depurar-dataset-completo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de observaciones 752494 con 11 variables (Entrenamiento)\n",
      "Cantidad de observaciones 322498 con 11 variables (Validación)\n"
     ]
    }
   ],
   "source": [
    "ataques_train = pd.read_csv('data/kddcup.data_clean_train.csv', sep=',', decimal='.')\n",
    "ataques_test = pd.read_csv('data/kddcup.data_clean_test.csv', sep=',', decimal='.')\n",
    "print(\"Cantidad de observaciones %i con %i variables (Entrenamiento)\" %(ataques_train.shape[0],ataques_train.shape[1]))\n",
    "print(\"Cantidad de observaciones %i con %i variables (Validación)\" %(ataques_test.shape[0],ataques_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otra forma de cargar los datos es utilizando el dataset de scikit-learn\n",
    "\n",
    "Utilizando [este enlace](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_kddcup99.html#sklearn.datasets.fetch_kddcup99) se pueden obtener los mismo datos ya preparados para realizar los diferentes análisis de mineria de datos y aprendizaje automático.\n",
    "\n",
    "``` python\n",
    "from sklearn import datasets\n",
    "# import some data to play with\n",
    "kddcup99 = datasets.fetch_kddcup99()\n",
    "X = kddcup99.data\n",
    "y = kddcup99.target\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>service_private</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>count</th>\n",
       "      <th>attack_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>probe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>probe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>213</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752487</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>17</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752488</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752489</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752490</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752491</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>27</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752492</th>\n",
       "      <td>0.12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>120</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752493</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EDA.printall(ataques_train, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a18709b00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAF2CAYAAAA8+zoXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAFAIgQcAAFAIgQcAAFAIgQcAAFCI/wfDIeYiPtpUgwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a187496a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Veamos la distribucción de los ataques\n",
    "ataques_train.attack_category.value_counts().plot(kind='bar', grid=True, figsize=(15, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal    568818\n",
       "dos       173290\n",
       "probe       9631\n",
       "r2l          720\n",
       "u2r           35\n",
       "Name: attack_category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ataques_train.attack_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>service_private</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>same_srv_rate</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.857361</td>\n",
       "      <td>-0.857416</td>\n",
       "      <td>-0.854746</td>\n",
       "      <td>-0.855662</td>\n",
       "      <td>0.875628</td>\n",
       "      <td>-0.855435</td>\n",
       "      <td>-0.798974</td>\n",
       "      <td>0.822824</td>\n",
       "      <td>-0.839728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <td>-0.857361</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996945</td>\n",
       "      <td>0.995208</td>\n",
       "      <td>0.997438</td>\n",
       "      <td>-0.798643</td>\n",
       "      <td>0.995120</td>\n",
       "      <td>0.728879</td>\n",
       "      <td>-0.709601</td>\n",
       "      <td>0.734496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flag_S0</th>\n",
       "      <td>-0.857416</td>\n",
       "      <td>0.996945</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993648</td>\n",
       "      <td>0.996796</td>\n",
       "      <td>-0.799382</td>\n",
       "      <td>0.994746</td>\n",
       "      <td>0.727246</td>\n",
       "      <td>-0.707233</td>\n",
       "      <td>0.734623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <td>-0.854746</td>\n",
       "      <td>0.995208</td>\n",
       "      <td>0.993648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993723</td>\n",
       "      <td>-0.796541</td>\n",
       "      <td>0.995738</td>\n",
       "      <td>0.728176</td>\n",
       "      <td>-0.710481</td>\n",
       "      <td>0.728736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <td>-0.855662</td>\n",
       "      <td>0.997438</td>\n",
       "      <td>0.996796</td>\n",
       "      <td>0.993723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.799982</td>\n",
       "      <td>0.996973</td>\n",
       "      <td>0.727520</td>\n",
       "      <td>-0.706967</td>\n",
       "      <td>0.732749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flag_SF</th>\n",
       "      <td>0.875628</td>\n",
       "      <td>-0.798643</td>\n",
       "      <td>-0.799382</td>\n",
       "      <td>-0.796541</td>\n",
       "      <td>-0.799982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.799754</td>\n",
       "      <td>-0.742058</td>\n",
       "      <td>0.712908</td>\n",
       "      <td>-0.744558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serror_rate</th>\n",
       "      <td>-0.855435</td>\n",
       "      <td>0.995120</td>\n",
       "      <td>0.994746</td>\n",
       "      <td>0.995738</td>\n",
       "      <td>0.996973</td>\n",
       "      <td>-0.799754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728622</td>\n",
       "      <td>-0.706946</td>\n",
       "      <td>0.728841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service_private</th>\n",
       "      <td>-0.798974</td>\n",
       "      <td>0.728879</td>\n",
       "      <td>0.727246</td>\n",
       "      <td>0.728176</td>\n",
       "      <td>0.727520</td>\n",
       "      <td>-0.742058</td>\n",
       "      <td>0.728622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.672443</td>\n",
       "      <td>0.641564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <td>0.822824</td>\n",
       "      <td>-0.709601</td>\n",
       "      <td>-0.707233</td>\n",
       "      <td>-0.710481</td>\n",
       "      <td>-0.706967</td>\n",
       "      <td>0.712908</td>\n",
       "      <td>-0.706946</td>\n",
       "      <td>-0.672443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.662356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>-0.839728</td>\n",
       "      <td>0.734496</td>\n",
       "      <td>0.734623</td>\n",
       "      <td>0.728736</td>\n",
       "      <td>0.732749</td>\n",
       "      <td>-0.744558</td>\n",
       "      <td>0.728841</td>\n",
       "      <td>0.641564</td>\n",
       "      <td>-0.662356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          same_srv_rate  dst_host_srv_serror_rate   flag_S0  \\\n",
       "same_srv_rate                  1.000000                 -0.857361 -0.857416   \n",
       "dst_host_srv_serror_rate      -0.857361                  1.000000  0.996945   \n",
       "flag_S0                       -0.857416                  0.996945  1.000000   \n",
       "dst_host_serror_rate          -0.854746                  0.995208  0.993648   \n",
       "srv_serror_rate               -0.855662                  0.997438  0.996796   \n",
       "flag_SF                        0.875628                 -0.798643 -0.799382   \n",
       "serror_rate                   -0.855435                  0.995120  0.994746   \n",
       "service_private               -0.798974                  0.728879  0.727246   \n",
       "dst_host_same_srv_rate         0.822824                 -0.709601 -0.707233   \n",
       "count                         -0.839728                  0.734496  0.734623   \n",
       "\n",
       "                          dst_host_serror_rate  srv_serror_rate   flag_SF  \\\n",
       "same_srv_rate                        -0.854746        -0.855662  0.875628   \n",
       "dst_host_srv_serror_rate              0.995208         0.997438 -0.798643   \n",
       "flag_S0                               0.993648         0.996796 -0.799382   \n",
       "dst_host_serror_rate                  1.000000         0.993723 -0.796541   \n",
       "srv_serror_rate                       0.993723         1.000000 -0.799982   \n",
       "flag_SF                              -0.796541        -0.799982  1.000000   \n",
       "serror_rate                           0.995738         0.996973 -0.799754   \n",
       "service_private                       0.728176         0.727520 -0.742058   \n",
       "dst_host_same_srv_rate               -0.710481        -0.706967  0.712908   \n",
       "count                                 0.728736         0.732749 -0.744558   \n",
       "\n",
       "                          serror_rate  service_private  \\\n",
       "same_srv_rate               -0.855435        -0.798974   \n",
       "dst_host_srv_serror_rate     0.995120         0.728879   \n",
       "flag_S0                      0.994746         0.727246   \n",
       "dst_host_serror_rate         0.995738         0.728176   \n",
       "srv_serror_rate              0.996973         0.727520   \n",
       "flag_SF                     -0.799754        -0.742058   \n",
       "serror_rate                  1.000000         0.728622   \n",
       "service_private              0.728622         1.000000   \n",
       "dst_host_same_srv_rate      -0.706946        -0.672443   \n",
       "count                        0.728841         0.641564   \n",
       "\n",
       "                          dst_host_same_srv_rate     count  \n",
       "same_srv_rate                           0.822824 -0.839728  \n",
       "dst_host_srv_serror_rate               -0.709601  0.734496  \n",
       "flag_S0                                -0.707233  0.734623  \n",
       "dst_host_serror_rate                   -0.710481  0.728736  \n",
       "srv_serror_rate                        -0.706967  0.732749  \n",
       "flag_SF                                 0.712908 -0.744558  \n",
       "serror_rate                            -0.706946  0.728841  \n",
       "service_private                        -0.672443  0.641564  \n",
       "dst_host_same_srv_rate                  1.000000 -0.662356  \n",
       "count                                  -0.662356  1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = ataques_train.corr()\n",
    "corr.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1ad28400>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAI1CAYAAAD4sNH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1d5849e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=False, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Esta comentado por que toma mucho tiempo producir el gráfico\n",
    "#datatograph = ataques_train[['same_srv_rate', 'dst_host_srv_serror_rate', 'flag_S0', 'dst_host_serror_rate', 'srv_serror_rate', 'flag_SF', 'serror_rate', 'service_private', 'dst_host_same_srv_rate', 'count']]\n",
    "# pd.plotting.scatter_matrix(ataques_train, alpha = 0.3, figsize = (14,14), diagonal = 'kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scatterplot](./data/scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de algoritmos y métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definimos los datos en entrenamiento y validación\n",
    "X_train = ataques_train.drop(['attack_category'], axis=1)\n",
    "y_train = ataques_train.attack_category.copy()\n",
    "\n",
    "X_test = ataques_test.drop(['attack_category'], axis=1)\n",
    "y_test = ataques_test.attack_category.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['same_srv_rate', 'dst_host_srv_serror_rate', 'flag_S0',\n",
       "       'dst_host_serror_rate', 'srv_serror_rate', 'flag_SF', 'serror_rate',\n",
       "       'service_private', 'dst_host_same_srv_rate', 'count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(311029, 10)\n",
      "(311029, 1)\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos de validación del 10% de la competencia \n",
    "ataques_10prec_test = pd.read_csv('data/data_10per_test_preprocessed.csv', sep=',', decimal='.')\n",
    "X_test_10perc = ataques_10prec_test[['same_srv_rate', 'dst_host_srv_serror_rate', 'flag_S0',\n",
    "       'dst_host_serror_rate', 'srv_serror_rate', 'flag_SF', 'serror_rate',\n",
    "       'service_private', 'dst_host_same_srv_rate', 'count']]\n",
    "\n",
    "print(X_test_10perc.shape)\n",
    "y_test_10perc = ataques_10prec_test[['attack_category']]\n",
    "print(y_test_10perc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión Datos Entranamiento:  0.992572698254\n",
      "Precisión Datos Validación:  0.991906926555\n",
      "--------------------------------------------------------------------------------\n",
      "[[ 73398    536     42      1      0]\n",
      " [   100 243830     46     19      1]\n",
      " [   124   1468   2636      1      0]\n",
      " [     1    254      0     24      0]\n",
      " [     0     17      0      0      0]]\n",
      "Tiempo total: 6.49s\n"
     ]
    }
   ],
   "source": [
    "# Árbol de decisión\n",
    "t0 = time()\n",
    "# Ajustamos un árbol de clasificación\n",
    "treeclf = DecisionTreeClassifier(random_state=1)\n",
    "treeclf.fit(X_train,y_train)\n",
    "# Verificamos la precisión de nuestro modelo, tanto como los datos de entrenamiento y los de validación\n",
    "print(\"Precisión Datos Entranamiento: \",treeclf.score(X_train,y_train))\n",
    "print(\"Precisión Datos Validación: \",treeclf.score(X_test,y_test))\n",
    "print(\"-\"*80)\n",
    "# Hacemos prediciones sobre los datos de validación\n",
    "y_pred = treeclf.predict(X_test)\n",
    "# Calcular y desplegar la matríz de confusión\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión Datos Validación 10%:  0.804690237888\n",
      "[[188866  33984    448      0      0      0]\n",
      " [   710  59530    344      8      1      0]\n",
      " [    26    476   1875      0      0      0]\n",
      " [     0   5970     12     11      0      0]\n",
      " [     0     39      0      0      0      0]\n",
      " [   340  17542    721    126      0      0]]\n",
      "Tiempo total: 1.92s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "print(\"Precisión Datos Validación 10%: \",treeclf.score(X_test_10perc,y_test_10perc))\n",
    "y_pred = treeclf.predict(X_test_10perc)\n",
    "# Calcular y desplegar la matríz de confusión\n",
    "cnf_matrix = confusion_matrix(y_test_10perc, y_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La precisión es algo baja teniendo en cuenta que en los datos de entrenamiento del conjunto de datos completo, no existen algunos tipos de ataques que aparecen en la dataset de validación del 10% y que fueron renombrados como desconocidos o \"unknown\"; adicional a esto los datos estan desbalanceados por lo que los ataques con poca frecuencia no son modelados bien, es necesario corregir la data antes de hacer estos análisis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceo de los datos originales\n",
    "\n",
    "Una forma de hacerlo sería tomar las observaciones del conjunto de datos completo y unirlas con las observaciones de los datos corregidos de validación; esto permitiría incluir las clases faltantes de tipos de ataques y estimar mejor las predicciones aumentando la precisión. Dado que los datos corregidos es lo último que tomaremos para poder validar la precisión de nuestro modelo con la del ganador del concurso, eso no sería lo correcto.\n",
    "\n",
    "Por otro lado, la otra forma de solucionar este problema es balancear el numero de datos por cada categoría a predecir y utilizar esta nueva muestra de entrenamiento en los análisis.\n",
    "\n",
    "Ahora bien, procedemos a balancear nuestros datos de muestra o entrenamiento extraidos del conjunto completo de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal    568818\n",
       "dos       173290\n",
       "probe       9631\n",
       "r2l          720\n",
       "u2r           35\n",
       "Name: attack_category, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ataques_train.attack_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Balanceo de los datos de forma manual, para entender un poco de que se trata\n",
    "# from sklearn.utils import resample\n",
    "# # Separamos en los datos en las diferentes clases\n",
    "# df_normal = ataques_train[ataques_train.attack_category=='normal']\n",
    "# df_dos = ataques_train[ataques_train.attack_category=='dos']\n",
    "# df_probe = ataques_train[ataques_train.attack_category=='probe']\n",
    "# df_r2l = ataques_train[ataques_train.attack_category=='r2l']\n",
    "# df_u2r = ataques_train[ataques_train.attack_category=='u2r']\n",
    "# #df_unknown = ataques_train[ataques_train.attack_category=='unknown']\n",
    "\n",
    "# # Upsample - remuestreo por encima, duplicando datos en las clases menores\n",
    "# # Esto termina con mas datos que la muestra original, afectando el rendimiento \n",
    "# # en algunos algoritmos si la muestra es grande\n",
    "# num_obs = df_normal.shape[0]\n",
    "# df_dos_upsampled = resample(df_dos, replace=True, n_samples=num_obs, random_state=123)\n",
    "# df_probe_upsampled = resample(df_probe, replace=True, n_samples=num_obs, random_state=123)\n",
    "# df_r2l_upsampled = resample(df_r2l, replace=True, n_samples=num_obs, random_state=123)\n",
    "# df_u2r_upsampled = resample(df_u2r, replace=True, n_samples=num_obs, random_state=123)\n",
    "\n",
    "# # Down-sample - Termina con menos datos que la muestra original\n",
    "# num_obs = df_u2r.shape[0]\n",
    "# df_normal_downsampled = resample(df_normal, replace=False, n_samples=num_obs, random_state=123)\n",
    "# df_dos_downsampled = resample(df_dos, replace=False, n_samples=num_obs, random_state=123)\n",
    "# df_probe_downsampled = resample(df_probe, replace=False, n_samples=num_obs, random_state=123)\n",
    "# df_r2l_downsampled = resample(df_r2l, replace=False, n_samples=num_obs, random_state=123)\n",
    "# # df_u2r_downsampled = resample(df_u2r, replace=False, n_samples=num_obs, random_state=123)\n",
    "\n",
    "\n",
    "# # Combinar las clases con los nuevos datos remuestreados\n",
    "# df_upsampled = pd.concat([df_normal, df_dos_upsampled, df_probe_upsampled, df_r2l_upsampled, df_u2r_upsampled])\n",
    "#  # Combinar las clases con los nuevos datos remuestreados\n",
    "# df_downsampled = pd.concat([df_normal_downsampled, df_dos_downsampled, df_probe_downsampled, df_r2l_downsampled, df_u2r])\n",
    " \n",
    "    \n",
    "# # Desplegar las cantidades de los nuevos datos\n",
    "# print(df_upsampled.attack_category.value_counts())\n",
    "# # Desplegar las cantidades de los nuevos datos\n",
    "# df_downsampled.attack_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal    568818\n",
       "r2l       568818\n",
       "dos       568818\n",
       "u2r       568818\n",
       "probe     568818\n",
       "Name: attack_category, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forma más eficiente y automatica\n",
    "# df2 = EDA.balanced_spl_by(ataques_train, 'attack_category', True) # True -> down sample, False -> up sample\n",
    "\n",
    "attack_category_group = ataques_train.groupby('attack_category')\n",
    "num_obs = attack_category_group.size().max() # up-sampling\n",
    "# num_obs = attack_category_group.size().min() # down-sampling\n",
    "# attack_category_group = attack_category_group.apply(lambda x: x.sample(num_obs, replace=False)).reset_index(drop=True)\n",
    "attack_category_group = attack_category_group.apply(lambda x: x.sample(num_obs, replace=True)).reset_index(drop=True)\n",
    "attack_category_group.attack_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2844090, 11)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_category_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión Datos Entranamiento:  0.815216818033\n",
      "Precisión Datos Validación:  0.815239672444\n",
      "--------------------------------------------------------------------------------\n",
      "[[112715    539    626     83     52]\n",
      " [   154  90073    288  10898  12033]\n",
      " [    26    774  77992    305  34539]\n",
      " [     0   1580      0  78546  33461]\n",
      " [     0   3305      0   6432 104397]]\n",
      "Tiempo total: 23.75s\n",
      "Precisión Datos Validación 10%:  0.756688283086\n",
      "[[189790  30916   2469     49     74      0]\n",
      " [   863  42434   7411   4322   5563      0]\n",
      " [    84    129   1856      4    304      0]\n",
      " [     2   3756     19   1263    953      0]\n",
      " [     0     20      0     10      9      0]\n",
      " [   259   9503   8595    237    135      0]]\n",
      "Tiempo total: 1.95s\n"
     ]
    }
   ],
   "source": [
    "# Árbol de decisión\n",
    "t0 = time()\n",
    "\n",
    "y = attack_category_group.attack_category.copy()\n",
    "X = attack_category_group.drop('attack_category', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=35)\n",
    "\n",
    "# Ajustamos un árbol de clasificación\n",
    "treeclf = DecisionTreeClassifier(random_state=1)\n",
    "treeclf.fit(X_train,y_train)\n",
    "# Verificamos la precisión de nuestro modelo, tanto como los datos de entrenamiento y los de validación\n",
    "print(\"Precisión Datos Entranamiento: \",treeclf.score(X_train,y_train))\n",
    "print(\"Precisión Datos Validación: \",treeclf.score(X_test,y_test))\n",
    "print(\"-\"*80)\n",
    "# Hacemos prediciones sobre los datos de validación\n",
    "y_pred = treeclf.predict(X_test)\n",
    "# Calcular y desplegar la matríz de confusión\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))\n",
    "t0 = time()\n",
    "print(\"Precisión Datos Validación 10%: \",treeclf.score(X_test_10perc,y_test_10perc))\n",
    "y_pred = treeclf.predict(X_test_10perc)\n",
    "# Calcular y desplegar la matríz de confusión\n",
    "cnf_matrix = confusion_matrix(y_test_10perc, y_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede observarse la precisión es mas baja que la anterior de (80.47%) pero clasifica mejor los datos de las frecuencias bajas de _probe, r2l y u2r_. De igual modo podriamos bajar un poco las frecuencias de los valores altos de la clase _normal y dos_ y probar con estos nuevos conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u2r       50000\n",
      "normal    50000\n",
      "probe     50000\n",
      "dos       50000\n",
      "r2l       50000\n",
      "Name: attack_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Balanceo de los datos de forma manual, para entender un poco de que se trata\n",
    "from sklearn.utils import resample\n",
    "# Separamos en los datos en las diferentes clases\n",
    "df_normal = ataques_train[ataques_train.attack_category=='normal']\n",
    "df_dos = ataques_train[ataques_train.attack_category=='dos']\n",
    "df_probe = ataques_train[ataques_train.attack_category=='probe']\n",
    "df_r2l = ataques_train[ataques_train.attack_category=='r2l']\n",
    "df_u2r = ataques_train[ataques_train.attack_category=='u2r']\n",
    "#df_unknown = ataques_train[ataques_train.attack_category=='unknown']\n",
    "\n",
    "# Remuestreo tomando solo un conjnto de datos menor en las clases de mayor frecuencia\n",
    "num_obs = 50000\n",
    "df_normal_downsampled = resample(df_normal, replace=False, n_samples=num_obs, random_state=123)\n",
    "df_dos_downsampled = resample(df_dos, replace=False, n_samples=num_obs, random_state=123)\n",
    "df_probe_upsampled = resample(df_probe, replace=True, n_samples=num_obs, random_state=123)\n",
    "df_r2l_upsampled = resample(df_r2l, replace=True, n_samples=num_obs, random_state=123)\n",
    "df_u2r_upsampled = resample(df_u2r, replace=True, n_samples=num_obs, random_state=123)\n",
    "\n",
    "# Combinar las clases con los nuevos datos remuestreados\n",
    "df_sampled = pd.concat([df_normal_downsampled, df_dos_downsampled, df_probe_upsampled, df_r2l_upsampled, df_u2r_upsampled])\n",
    "    \n",
    "# Desplegar las cantidades de los nuevos datos\n",
    "print(df_sampled.attack_category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión Datos Entranamiento:  0.813925\n",
      "Precisión Datos Validación:  0.81108\n",
      "--------------------------------------------------------------------------------\n",
      "[[9866   54   74   13    5]\n",
      " [  34 7938   40  989 1112]\n",
      " [  22   68 6725   35 3077]\n",
      " [   0  148    0 6825 2960]\n",
      " [   0  302    0  513 9200]]\n",
      "Tiempo total: 1.37s\n",
      "Precisión Datos Validación 10%:  0.774426178909\n",
      "[[195513  25196   2475     40     74      0]\n",
      " [   926  42296   7476   4331   5564      0]\n",
      " [    94    126   1770     83    304      0]\n",
      " [     0   3728     31   1281    953      0]\n",
      " [     0     20      0     10      9      0]\n",
      " [   586   8976   8796    236    135      0]]\n",
      "Tiempo total: 1.97s\n"
     ]
    }
   ],
   "source": [
    "# Árbol de decisión\n",
    "t0 = time()\n",
    "\n",
    "y = df_sampled.attack_category.copy()\n",
    "X = df_sampled.drop('attack_category', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=35)\n",
    "\n",
    "# Ajustamos un árbol de clasificación\n",
    "treeclf = DecisionTreeClassifier(random_state=1)\n",
    "treeclf.fit(X_train,y_train)\n",
    "# Verificamos la precisión de nuestro modelo, tanto como los datos de entrenamiento y los de validación\n",
    "print(\"Precisión Datos Entranamiento: \",treeclf.score(X_train,y_train))\n",
    "print(\"Precisión Datos Validación: \",treeclf.score(X_test,y_test))\n",
    "print(\"-\"*80)\n",
    "# Hacemos prediciones sobre los datos de validación\n",
    "y_pred = treeclf.predict(X_test)\n",
    "# Calcular y desplegar la matríz de confusión\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))\n",
    "t0 = time()\n",
    "print(\"Precisión Datos Validación 10%: \",treeclf.score(X_test_10perc,y_test_10perc))\n",
    "y_pred = treeclf.predict(X_test_10perc)\n",
    "# Calcular y desplegar la matríz de confusión\n",
    "cnf_matrix = confusion_matrix(y_test_10perc, y_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa solo mejora un poco la precisión, aunque los procesos son mas eficientes al reducir la dimensionalidad de la muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal    50000\n",
      "dos       50000\n",
      "probe      9631\n",
      "r2l         720\n",
      "u2r          35\n",
      "Name: attack_category, dtype: int64\n",
      "Precisión Datos Entranamiento:  0.962551524211\n",
      "Precisión Datos Validación:  0.957786031343\n",
      "--------------------------------------------------------------------------------\n",
      "[[ 9802    67    40     0     1]\n",
      " [   28 10003    20     3     1]\n",
      " [   48   597  1317     0     0]\n",
      " [    0   120     0    24     0]\n",
      " [    0     7     0     0     0]]\n",
      "Tiempo total: 0.71s\n",
      "Precisión Datos Validación 10%:  0.804638795739\n",
      "[[196042  26140   1116      0      0      0]\n",
      " [   166  52225   8178     23      1      0]\n",
      " [    85    335   1957      0      0      0]\n",
      " [     0   5928     23     42      0      0]\n",
      " [     0     37      1      1      0      0]\n",
      " [   355   9294   8890    190      0      0]]\n",
      "Tiempo total: 2.09s\n"
     ]
    }
   ],
   "source": [
    "# Ultima prueba con los datos de las clases normal y dos remuestreadas, dejando el resto igual\n",
    "# Separamos en los datos en las diferentes clases\n",
    "df_normal = ataques_train[ataques_train.attack_category=='normal']\n",
    "df_dos = ataques_train[ataques_train.attack_category=='dos']\n",
    "df_probe = ataques_train[ataques_train.attack_category=='probe']\n",
    "df_r2l = ataques_train[ataques_train.attack_category=='r2l']\n",
    "df_u2r = ataques_train[ataques_train.attack_category=='u2r']\n",
    "#df_unknown = ataques_train[ataques_train.attack_category=='unknown']\n",
    "\n",
    "# Remuestreo tomando solo un conjnto de datos menor en las clases de mayor frecuencia\n",
    "num_obs = 50000\n",
    "df_normal_downsampled = resample(df_normal, replace=False, n_samples=num_obs, random_state=123)\n",
    "df_dos_downsampled = resample(df_dos, replace=False, n_samples=num_obs, random_state=123)\n",
    "\n",
    "# Combinar las clases con los nuevos datos remuestreados\n",
    "df_sampled = pd.concat([df_normal_downsampled, df_dos_downsampled, df_probe, df_r2l, df_u2r])\n",
    "    \n",
    "# Desplegar las cantidades de los nuevos datos\n",
    "print(df_sampled.attack_category.value_counts())\n",
    "\n",
    "# Árbol de decisión\n",
    "t0 = time()\n",
    "\n",
    "y = df_sampled.attack_category.copy()\n",
    "X = df_sampled.drop('attack_category', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=35)\n",
    "\n",
    "# Ajustamos un árbol de clasificación\n",
    "treeclf = DecisionTreeClassifier(random_state=1)\n",
    "treeclf.fit(X_train,y_train)\n",
    "# Verificamos la precisión de nuestro modelo, tanto como los datos de entrenamiento y los de validación\n",
    "print(\"Precisión Datos Entranamiento: \",treeclf.score(X_train,y_train))\n",
    "print(\"Precisión Datos Validación: \",treeclf.score(X_test,y_test))\n",
    "print(\"-\"*80)\n",
    "# Hacemos prediciones sobre los datos de validación\n",
    "y_pred = treeclf.predict(X_test)\n",
    "# Calcular y desplegar la matríz de confusión\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))\n",
    "t0 = time()\n",
    "print(\"Precisión Datos Validación 10%: \",treeclf.score(X_test_10perc,y_test_10perc))\n",
    "y_pred = treeclf.predict(X_test_10perc)\n",
    "# Calcular y desplegar la matríz de confusión\n",
    "cnf_matrix = confusion_matrix(y_test_10perc, y_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que mejora la precisión pero no identifica bien los datos de bajas frecuencias volviendo al problema del inicio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remuestreo o balance de los datos final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dos       10000\n",
      "u2r       10000\n",
      "r2l       10000\n",
      "normal    10000\n",
      "probe     10000\n",
      "Name: attack_category, dtype: int64\n",
      "Precisión Datos Entranamiento:  0.81705\n",
      "Precisión Datos Validación:  0.8081\n",
      "--------------------------------------------------------------------------------\n",
      "[[2002   12   20    1    0]\n",
      " [   7 1556   16  197  230]\n",
      " [  15   13 1317    6  602]\n",
      " [   0   36    0 1346  563]\n",
      " [   0   72    0  129 1860]]\n",
      "Tiempo total: 0.29s\n",
      "Precisión Datos Validación 10%:  0.756492159895\n",
      "[[190039  30537   2601     47     74      0]\n",
      " [   900  42152   7526   4439   5576      0]\n",
      " [    88    122   1863      0    304      0]\n",
      " [     0   3761     51   1228    953      0]\n",
      " [     0     15      1     14      9      0]\n",
      " [   706   8804   8743    337    139      0]]\n",
      "Tiempo total: 2.15s\n"
     ]
    }
   ],
   "source": [
    "# Separamos en los datos en las diferentes clases\n",
    "df_normal = ataques_train[ataques_train.attack_category=='normal']\n",
    "df_dos = ataques_train[ataques_train.attack_category=='dos']\n",
    "df_probe = ataques_train[ataques_train.attack_category=='probe']\n",
    "df_r2l = ataques_train[ataques_train.attack_category=='r2l']\n",
    "df_u2r = ataques_train[ataques_train.attack_category=='u2r']\n",
    "#df_unknown = ataques_train[ataques_train.attack_category=='unknown']\n",
    "\n",
    "# Remuestreo tomando solo un conjnto de datos menor en las clases de mayor frecuencia\n",
    "num_obs = 10000\n",
    "df_normal_downsampled = resample(df_normal, replace=False, n_samples=num_obs, random_state=123)\n",
    "df_dos_downsampled = resample(df_dos, replace=False, n_samples=num_obs, random_state=123)\n",
    "df_probe_upsampled = resample(df_probe, replace=True, n_samples=num_obs, random_state=123)\n",
    "df_r2l_upsampled = resample(df_r2l, replace=True, n_samples=num_obs, random_state=123)\n",
    "df_u2r_upsampled = resample(df_u2r, replace=True, n_samples=num_obs, random_state=123)\n",
    "\n",
    "# Combinar las clases con los nuevos datos remuestreados\n",
    "df_sampled = pd.concat([df_normal_downsampled, df_dos_downsampled, df_probe_upsampled, df_r2l_upsampled, df_u2r_upsampled])\n",
    "    \n",
    "# Desplegar las cantidades de los nuevos datos\n",
    "print(df_sampled.attack_category.value_counts())\n",
    "\n",
    "# Árbol de decisión\n",
    "t0 = time()\n",
    "\n",
    "y = df_sampled.attack_category.copy()\n",
    "X = df_sampled.drop('attack_category', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=35)\n",
    "\n",
    "# Ajustamos un árbol de clasificación\n",
    "treeclf = DecisionTreeClassifier(random_state=1)\n",
    "treeclf.fit(X_train,y_train)\n",
    "# Verificamos la precisión de nuestro modelo, tanto como los datos de entrenamiento y los de validación\n",
    "print(\"Precisión Datos Entranamiento: \",treeclf.score(X_train,y_train))\n",
    "print(\"Precisión Datos Validación: \",treeclf.score(X_test,y_test))\n",
    "print(\"-\"*80)\n",
    "# Hacemos prediciones sobre los datos de validación\n",
    "y_pred = treeclf.predict(X_test)\n",
    "# Calcular y desplegar la matríz de confusión\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))\n",
    "t0 = time()\n",
    "print(\"Precisión Datos Validación 10%: \",treeclf.score(X_test_10perc,y_test_10perc))\n",
    "y_pred = treeclf.predict(X_test_10perc)\n",
    "# Calcular y desplegar la matríz de confusión\n",
    "cnf_matrix = confusion_matrix(y_test_10perc, y_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.959778965486\n",
      "[[ 9820    70    20     0     0]\n",
      " [   12 10023    17     2     1]\n",
      " [   42   596  1323     0     1]\n",
      " [    0   120     0    24     0]\n",
      " [    0     7     0     0     0]]\n",
      "Precisión usando Random Forest:  0.796552733025\n",
      "[[192416  29189   1693      0      0      0]\n",
      " [   831  53363   6382     17      0      0]\n",
      " [    13    441   1923      0      0      0]\n",
      " [     0   5920     24     49      0      0]\n",
      " [     0     37      0      2      0      0]\n",
      " [   418  11644   6644     23      0      0]]\n",
      "Tiempo total: 6.74s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# Algunos de los parametros son extraidos de análisis anteriores\n",
    "rfclf = RandomForestClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
    "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=3,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
    "            oob_score=False, random_state=12345, verbose=0, warm_start=False)\n",
    "\n",
    "# # Ajustamos el mejor algortimo para los datos de las 40 variables \n",
    "rfclf.fit(X_train, y_train)\n",
    "predictions = rfclf.predict(X_test)\n",
    "print(\"Precisión: \", accuracy_score(y_test, predictions))\n",
    "# Calcular y desplegar la matríz de confusión\n",
    "cnf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(cnf_matrix)\n",
    "\n",
    "# X_test_10perc,y_test_10perc\n",
    "predictions = rfclf.predict(X_test_10perc)\n",
    "print(\"Precisión usando Random Forest: \", accuracy_score(y_test_10perc, predictions))\n",
    "# Calcular y desplegar la matríz de confusión\n",
    "cnf_matrix = confusion_matrix(y_test_10perc, predictions)\n",
    "print(cnf_matrix)\n",
    "\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest con Boostrap o remuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.95968837757\n",
      "[[ 9820    75    15     0     0]\n",
      " [   11 10025    17     2     0]\n",
      " [   43   596  1319     0     4]\n",
      " [    0   120     0    24     0]\n",
      " [    0     7     0     0     0]]\n",
      "Precisión usando Random Forest:  0.792639914606\n",
      "[[191051  30630   1617      0      0      0]\n",
      " [   764  53390   6421     17      1      0]\n",
      " [    12    323   2042      0      0      0]\n",
      " [     0   5920     22     51      0      0]\n",
      " [     0     38      0      1      0      0]\n",
      " [   404  11685   6635      5      0      0]]\n",
      "Tiempo total: 24.90s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# Algunos de los parametros son extraidos de análisis anteriores\n",
    "rfclf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=3,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
    "            oob_score=False, random_state=12345, verbose=0, warm_start=False)\n",
    "\n",
    "# # Ajustamos el mejor algortimo para los datos de las 40 variables \n",
    "rfclf.fit(X_train, y_train)\n",
    "predictions = rfclf.predict(X_test)\n",
    "print(\"Precisión: \", accuracy_score(y_test, predictions))\n",
    "# Calcular y desplegar la matríz de confusión\n",
    "cnf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(cnf_matrix)\n",
    "\n",
    "# X_test_10perc,y_test_10perc\n",
    "predictions = rfclf.predict(X_test_10perc)\n",
    "print(\"Precisión usando Random Forest: \", accuracy_score(y_test_10perc, predictions))\n",
    "# Calcular y desplegar la matríz de confusión\n",
    "cnf_matrix = confusion_matrix(y_test_10perc, predictions)\n",
    "print(cnf_matrix)\n",
    "\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grupo 1 precisión: 0.9596874646132941\n",
      "Grupo 2 precisión: 0.9570830030574113\n",
      "Grupo 3 precisión: 0.9550447287962858\n",
      "Grupo 4 precisión: 0.9629713509228853\n",
      "Grupo 5 precisión: 0.9598007020722455\n",
      "Grupo 6 precisión: 0.9551579662552372\n",
      "Grupo 7 precisión: 0.958328615105877\n",
      "Grupo 8 precisión: 0.9594609896953913\n",
      "Grupo 9 precisión: 0.9557191392978482\n",
      "Grupo 10 precisión: 0.9614949037372593\n",
      "Precisión promedio: 0.9584748863553735\n",
      "Tiempo total: 151.68s\n"
     ]
    }
   ],
   "source": [
    "# Validación Cruzada con KFold\n",
    "t0 = time()\n",
    "run_kfold(rfclf, X_train, y_train)\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957489702509\n",
      "Puntaje:  0.958238970921\n",
      "[[ 9806    66    38     0     0]\n",
      " [   25 10008    19     2     1]\n",
      " [   45   598  1318     0     1]\n",
      " [    0   120     0    24     0]\n",
      " [    0     7     0     0     0]]\n",
      "Precisión validación Extra Trees:  0.803754633812\n",
      "[[195658  25519   2121      0      0      0]\n",
      " [   153  52267   8158     15      0      0]\n",
      " [    10    349   2018      0      0      0]\n",
      " [     0   5925     20     48      0      0]\n",
      " [     0     38      0      1      0      0]\n",
      " [   263   9409   8827    230      0      0]]\n",
      "Tiempo total: 64.83s\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Classification\n",
    "t0 = time()\n",
    "seed = 7\n",
    "num_trees = 100\n",
    "max_features = 7\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "model = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(results.mean())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "precision = model.score(X_test, y_test)\n",
    "print(\"Puntaje: \",precision)\n",
    "# Predicciones\n",
    "y_pred_class = model.predict(X_test)\n",
    "# Matríz de correlación\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred_class)\n",
    "print(cnf_matrix)\n",
    "\n",
    "precision = model.score(X_test_10perc,y_test_10perc)\n",
    "print(\"Precisión validación Extra Trees: \",precision)\n",
    "# Predicciones\n",
    "y_pred_class = model.predict(X_test_10perc)\n",
    "# Matríz de correlación\n",
    "cnf_matrix = confusion_matrix(y_test_10perc, y_pred_class)\n",
    "print(cnf_matrix)\n",
    "\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dos        223298\n",
       "normal      60593\n",
       "unknown     18729\n",
       "r2l          5993\n",
       "probe        2377\n",
       "u2r            39\n",
       "Name: attack_category, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_10perc.attack_category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árboles de Decisión con Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.957559561554\n",
      "[[ 9789    69    52     0     0]\n",
      " [   23 10005    24     2     1]\n",
      " [   40   595  1323     0     4]\n",
      " [    0   120     0    24     0]\n",
      " [    0     7     0     0     0]]\n",
      "Precisión usando Árboles con Bagging:  0.80106356642\n",
      "[[194889  27136   1273      0      0      0]\n",
      " [   132  52257   8182     19      3      0]\n",
      " [    80    330   1967      0      0      0]\n",
      " [     0   5933     19     41      0      0]\n",
      " [     0     37      1      1      0      0]\n",
      " [   387   9173   9000    169      0      0]]\n",
      "Tiempo total: 16.70s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "clf_bagging = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True)\n",
    "\n",
    "clf_bagging.fit(X_train, y_train)\n",
    "y_pred = clf_bagging.predict(X_test)\n",
    "#metrics.f1_score(y_pred, y_test) \n",
    "print(\"Precisión: \",metrics.accuracy_score(y_pred, y_test))\n",
    "# Calcular y desplegar la matríz de confusión\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cnf_matrix)\n",
    "\n",
    "# X_test_10perc,y_test_10perc\n",
    "y_pred = clf_bagging.predict(X_test_10perc)\n",
    "print(\"Precisión usando Árboles con Bagging: \",metrics.accuracy_score(y_pred, y_test_10perc))\n",
    "# Calcular y desplegar la matríz de confusión\n",
    "cnf_matrix = confusion_matrix(y_test_10perc, y_pred)\n",
    "print(cnf_matrix)\n",
    "\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Validación GBRT:  0.668448229006\n",
      "[[5904  865   11 2958  172]\n",
      " [  24 8412  161  597  861]\n",
      " [ 442  760  413  223  124]\n",
      " [   1  109    1   29    4]\n",
      " [   0    5    0    2    0]]\n",
      "Score Validación GBRT:  0.678611962229\n",
      "[[160575  45262     26  17302    133      0]\n",
      " [  1993  49924    163   1500   7013      0]\n",
      " [   857    414    246    221    639      0]\n",
      " [     3   2428     29    320   3213      0]\n",
      " [     0     19      4     13      3      0]\n",
      " [  2846  12422    134    875   2452      0]]\n",
      "Tiempo total: 745.73s\n"
     ]
    }
   ],
   "source": [
    "# GBRT\n",
    "t0 = time()\n",
    "\n",
    "gbclf = GradientBoostingClassifier(n_estimators=500, learning_rate=1.0, max_depth=5, random_state=0)\n",
    "gbclf.fit(X_train, y_train)\n",
    "\n",
    "precision = gbclf.score(X_test, y_test)\n",
    "print(\"Puntaje: \",precision)\n",
    "y_pred_class = gbclf.predict(X_test) # Predicciones\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred_class) # Matríz de correlación\n",
    "print(cnf_matrix)\n",
    "\n",
    "precision = gbclf.score(X_test_10perc,y_test_10perc)\n",
    "print(\"Score Validación GBRT: \",precision)\n",
    "y_pred_class = gbclf.predict(X_test_10perc) # Predicciones\n",
    "cnf_matrix = confusion_matrix(y_test_10perc, y_pred_class) # Matríz de correlación\n",
    "print(cnf_matrix)\n",
    "\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684511992258\n",
      "0.704683395235\n",
      "Score Validación AdaBoost:  0.704683395235\n",
      "Tiempo total: 325.28s\n",
      "Score Validación AdaBoost:  0.802732221111\n",
      "[[222783    491     24      0      0      0]\n",
      " [ 28154  26035   6387     16      1      0]\n",
      " [  1262    310    805      0      0      0]\n",
      " [     7   5895     41     50      0      0]\n",
      " [     2     27      8      2      0      0]\n",
      " [  4071   8624   5701    333      0      0]]\n",
      "Tiempo total: 70.32s\n"
     ]
    }
   ],
   "source": [
    "# Utilizando AdaBoost\n",
    "t0 = time()\n",
    "\n",
    "# Create and fit an AdaBoosted decision tree\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=15), n_estimators=500) # algorithm=\"SAMME\", algorithm=\"SAMME.R\", learning_rate=1.0\n",
    "\n",
    "bdt.fit(X_train, y_train)\n",
    "scores = cross_val_score(bdt, X_train, y_train)\n",
    "print(scores.mean())\n",
    "\n",
    "y_pred = bdt.predict(X_test)\n",
    "print(metrics.accuracy_score(y_pred, y_test))\n",
    "precision = bdt.score(X_test, y_test)\n",
    "print(\"Score Validación AdaBoost: \",precision)\n",
    "\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))\n",
    "\n",
    "t0 = time()\n",
    "precision = bdt.score(X_test_10perc, y_test_10perc)\n",
    "print(\"Score Validación AdaBoost: \",precision)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_class = bdt.predict(X_test_10perc)\n",
    "cnf_matrix = confusion_matrix(y_test_10perc, y_pred_class) # Matríz de correlación\n",
    "print(cnf_matrix)\n",
    "\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 95.79%\n",
      "Precisión con XGBoost: 80.75%\n",
      "[[195708  26301   1289      0      0      0]\n",
      " [   832  53388   6350     21      2      0]\n",
      " [    19    331   2027      0      0      0]\n",
      " [     0   5936     24     33      0      0]\n",
      " [     0     38      1      0      0      0]\n",
      " [   367  11504   6652    206      0      0]]\n",
      "Tiempo total: 1239.80s\n"
     ]
    }
   ],
   "source": [
    "# Ajustar o entrenar el modelo\n",
    "t0 = time()\n",
    "\n",
    "model = XGBClassifier(booster=\"gbtree\", max_depth=15, n_estimators=1000, n_jobs=-1, random_state=12345, silent=True)\n",
    "model.fit(X_train, y_train)\n",
    "# hacer predicciones sobre los datos de prueba extraidos de los de entrenamiento\n",
    "y_pred = model.predict(X_test)\n",
    "# predictions = [round(value) for value in y_pred] # Usualmente se hace cuando la variable independiente es ordinal\n",
    "# Evaluar las predicciones\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# Hacer predicciones sobre los datos de validación completos\n",
    "y_pred = model.predict(X_test_10perc)\n",
    "# Evaluar las predicciones\n",
    "accuracy = accuracy_score(y_test_10perc, y_pred)\n",
    "print(\"Precisión con XGBoost: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test_10perc, y_pred) # Matríz de correlación\n",
    "print(cnf_matrix)\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis - LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 92.78%\n",
      "Precisión con Linear Discriminant Analysis: 38.01%\n",
      "[[ 57628 165330    291      1     48      0]\n",
      " [    14  59651    868     31     29      0]\n",
      " [  1163    310    904      0      0      0]\n",
      " [     0   5930     35     27      1      0]\n",
      " [     0     35      0      4      0      0]\n",
      " [   648  16448   1185    301    147      0]]\n",
      "Tiempo total: 2.01s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "clflda = LinearDiscriminantAnalysis(n_components=5, solver=\"svd\") # solver=\"lsqr\" \n",
    "#clflda = QuadraticDiscriminantAnalysis()\n",
    "clflda.fit(X_train, y_train)\n",
    "y_pred = clflda.predict(X_test)\n",
    "# Evaluar las predicciones\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# Hacer predicciones sobre los datos de validación completos\n",
    "y_pred = clflda.predict(X_test_10perc)\n",
    "accuracy = accuracy_score(y_test_10perc, y_pred) # Evaluar las predicciones\n",
    "print(\"Precisión con Linear Discriminant Analysis: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test_10perc, y_pred) # Matríz de correlación\n",
    "print(cnf_matrix)\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dos', 'normal', 'probe', 'r2l', 'u2r'], \n",
       "      dtype='<U6')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clflda.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN con Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score :  0.945058429206\n",
      "[[ 9726   174    10     0     0]\n",
      " [    0 10048     7     0     0]\n",
      " [  108   771  1083     0     0]\n",
      " [    0   134     2     8     0]\n",
      " [    0     7     0     0     0]]\n",
      "Score Validación KNN con Bagging:  0.382636345807\n",
      "[[ 57367 165292    639      0      0      0]\n",
      " [   574  59706    312      1      0      0]\n",
      " [    67    372   1938      0      0      0]\n",
      " [     0   5991      2      0      0      0]\n",
      " [     0     39      0      0      0      0]\n",
      " [   421  17460    848      0      0      0]]\n",
      "Tiempo total: 303.72s\n"
     ]
    }
   ],
   "source": [
    "# Bagging with KNN - toma algo de tiempo 5min\n",
    "t0 = time()\n",
    "\n",
    "knnclf_bagging = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5, n_estimators=10, \n",
    "                                bootstrap=True, random_state=42, n_jobs=-1, oob_score=False )\n",
    "\n",
    "knnclf_bagging.fit(X_train, y_train)\n",
    "y_pred = knnclf_bagging.predict(X_test)\n",
    "print(\"Score : \", metrics.accuracy_score(y_pred, y_test))\n",
    "# Matríz de correlación\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cnf_matrix)\n",
    "\n",
    "# Datos validación concurso\n",
    "y_pred_class = knnclf_bagging.predict(X_test_10perc) # Hacer predicciones\n",
    "print(\"Score Validación KNN con Bagging: \", metrics.accuracy_score(y_pred_class, y_test_10perc))\n",
    "cnf_matrix = confusion_matrix(y_test_10perc, y_pred_class) # Matríz de correlación\n",
    "print(cnf_matrix)\n",
    "\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensamble (Staking o Voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total: 3.10s\n",
      "Precisión:  0.957559561554\n",
      "[[ 9818    72    20     0     0]\n",
      " [   15 10013    23     3     1]\n",
      " [   79   597  1286     0     0]\n",
      " [    0   120     0    24     0]\n",
      " [    0     7     0     0     0]]\n",
      "Precisión con Voting:  0.805741586797\n",
      "[[195779  26957    562      0      0      0]\n",
      " [   672  52848   7052     20      1      0]\n",
      " [   118    318   1941      0      0      0]\n",
      " [     0   5929     23     41      0      0]\n",
      " [     0     38      0      1      0      0]\n",
      " [   461  10495   7602    171      0      0]]\n",
      "Tiempo total: 42.35s\n"
     ]
    }
   ],
   "source": [
    "# Training classifiers\n",
    "t0 = time()\n",
    "clf1 = DecisionTreeClassifier(max_depth=15)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=5)\n",
    "#clf3 = SVC(kernel='rbf', probability=True)\n",
    "#eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)], voting='soft', weights=[2,1,2])\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2)], voting='soft', weights=[1,1])\n",
    "\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "#clf3 = clf3.fit(X_train, y_train) # Esto toma demasiado tiempo\n",
    "\n",
    "eclf = eclf.fit(X_train, y_train)\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "precision = eclf.score(X_test, y_test)\n",
    "print(\"Precisión: \",precision)\n",
    "y_pred_class = eclf.predict(X_test)\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred_class) # Matríz de correlación\n",
    "print(cnf_matrix)\n",
    "\n",
    "# Validamos los datos de prueba\n",
    "precision = eclf.score(X_test_10perc, y_test_10perc)\n",
    "print(\"Precisión con Voting: \",precision)\n",
    "y_pred_class = eclf.predict(X_test_10perc)\n",
    "cnf_matrix = confusion_matrix(y_test_10perc, y_pred_class) # Matríz de correlación\n",
    "print(cnf_matrix)\n",
    "\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se aprecia, no se utilizaron métodos rigurozamente escogidos, sino solo dos para mostrar la bonda del clasificador. Se debe realizar un clasificador con los mejores vistos arriba y mirar que sucede con la presición del modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen de los métodos utilizados\n",
    "\n",
    "| MODELO                                                 \t\t\t| Validación | \n",
    "| --- | --- |\n",
    "| 1. Árbol de decisión (datos desbalanceados)                       | 80.47% |\n",
    "| 2. Árbol de decisión (datos balanceados up-sample)                | 75.67% |\n",
    "| 3. Árbol de decisión (datos balanceados down-sample)              | 77.44% |\n",
    "| 4. Árbol de decisión (datos balanceados updown-sample)            | 80.46% |\n",
    "| 5. Árbol de decisión (datos balanceados up-sample 10k obs)        | 75.65% |\n",
    "| 6. Random Forest                                                  | 79.66% |\n",
    "| 7. Random Forest con Boostrap o remuestreo                        | 79.26% |\n",
    "| 8. Extra Trees Classification                                     | 80.38% |\n",
    "| 9. Árboles de Decisión con Bagging                                | 80.11% |\n",
    "| 10. Gradient Boosting                                             | 67.86% |\n",
    "| 11. AdaBoost                                                      | 80.27% |\n",
    "| 12. XGBoost                                                       | 80.75% |\n",
    "| 13. Linear Discriminant Analysis - LDA                            | 38.01% |\n",
    "| 14. KNN con Bagging                                               | 38.26% |\n",
    "| 15. Emsable (Staking o Voting)                                    | 80.57% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que los resultados son muy similares en la mayoría de los modelos implementados, pero con ciertos predictores que no representan bien los datos procesados. El hecho de que hayan datos duplicados, muestras mal balanceadas, y observaciones nuevas con alta frecuencia, hace que los modelos no puedan estimar o predecir con mayor precisión el conjunto de datos completo incluyendo los datos de validación.\n",
    "\n",
    "Para mejorar un poco las predicciones se puede mejorar los datos de entrenamiento, utilizar más variables importantes (_aquí solo estamos tomando 10_) y ajustar mejor los parametros de los estimadores.\n",
    "\n",
    "A continuación haremos un ejercicio no exhaustivo utilizando estos cambios con los modelos que mejor precisión ofrecieron en las pruebas anteriores (_ExtraTrees, AdaBoost, XGBoost y Voting_), de igual manera al final probaremos a manera de ejemplo un modelo con redes neuronales para ver que tambien se ajusta a los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de observaciones 1074992 con 122 variables: \n",
      "Cantidad de observaciones 1074992 con 41 variables (Entrenamiento) \n",
      "Cantidad de observaciones 311029 con 41 variables (Validación) \n",
      "Balanceo de datos: \n",
      "normal    200000\n",
      "dos       100000\n",
      "probe      13860\n",
      "r2l          999\n",
      "u2r           52\n",
      "Name: attack_category, dtype: int64\n",
      "dos       223298\n",
      "normal     60593\n",
      "r2l         5993\n",
      "probe       2377\n",
      "u2r           39\n",
      "Name: attack_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos completos para seleccionar mas variables\n",
    "ataques_train = pd.read_csv('data/kddcup.data_clean.csv', sep=',', decimal='.')\n",
    "print(\"Cantidad de observaciones %i con %i variables: \" %(ataques_train.shape[0],ataques_train.shape[1]))\n",
    "feature_cols = ['same_srv_rate', 'flag_SF', 'dst_host_same_srv_rate', 'service_private',\n",
    "       'dst_host_srv_serror_rate', 'service_http', 'logged_in',\n",
    "       'dst_host_srv_count', 'count', 'srv_serror_rate', 'flag_S0',\n",
    "       'dst_host_serror_rate', 'dst_host_count', 'rerror_rate', 'serror_rate',\n",
    "       'dst_host_rerror_rate', 'src_bytes', 'srv_rerror_rate',\n",
    "       'dst_host_same_src_port_rate', 'dst_host_srv_rerror_rate',\n",
    "       'protocol_type_udp', 'service_ecr_i', 'flag_REJ', 'service_pop_3',\n",
    "       'protocol_type_tcp', 'diff_srv_rate', 'hot', 'dst_host_diff_srv_rate',\n",
    "       'service_telnet', 'service_domain_u', 'wrong_fragment',\n",
    "       'dst_host_srv_diff_host_rate', 'num_compromised', 'service_smtp',\n",
    "       'srv_count', 'dst_bytes', 'srv_diff_host_rate', 'service_ftp_data',\n",
    "       'duration', 'service_ftp', 'attack_category']\n",
    "\n",
    "ataques_train = ataques_train[feature_cols]\n",
    "# Cargamos los datos de validación del 10% de la competencia \n",
    "#ataques_10prec_test = pd.read_csv('data/data_10per_test_preprocessed.csv', sep=',', decimal='.')\n",
    "ataques_test = ataques_10prec_test[feature_cols]\n",
    "\n",
    "print(\"Cantidad de observaciones %i con %i variables (Entrenamiento) \" %(ataques_train.shape[0],ataques_train.shape[1]))\n",
    "print(\"Cantidad de observaciones %i con %i variables (Validación) \" %(ataques_test.shape[0],ataques_test.shape[1]))\n",
    "\n",
    "# Balanceamos los datos\n",
    "df_normal = ataques_train[ataques_train.attack_category=='normal']\n",
    "df_dos = ataques_train[ataques_train.attack_category=='dos']\n",
    "df_probe = ataques_train[ataques_train.attack_category=='probe']\n",
    "df_r2l = ataques_train[ataques_train.attack_category=='r2l']\n",
    "df_u2r = ataques_train[ataques_train.attack_category=='u2r']\n",
    "#df_unknown = ataques_train[ataques_train.attack_category=='unknown']\n",
    "\n",
    "# Remuestreo tomando solo un conjnto de datos menor en las clases de mayor frecuencia\n",
    "df_normal_downsampled = resample(df_normal, replace=False, n_samples=200000, random_state=123)\n",
    "df_dos_downsampled = resample(df_dos, replace=False, n_samples=100000, random_state=123)\n",
    "# Combinar las clases con los nuevos datos remuestreados\n",
    "ataques_train = pd.concat([df_normal_downsampled, df_dos_downsampled, df_probe, df_r2l, df_u2r])\n",
    "\n",
    "# Eliminamos los datos \"unknown\" de la muestra de validación, los cuales no tenemos como entrenar\n",
    "ataques_test = ataques_test[ataques_test.attack_category!='unknown']\n",
    "\n",
    "# Mostrar las cantidades de los nuevos datos\n",
    "print(\"Balanceo de datos: \")\n",
    "print(ataques_train.attack_category.value_counts())\n",
    "print(ataques_test.attack_category.value_counts())\n",
    "\n",
    "# Definimos los datos en entrenamiento y validación\n",
    "X = ataques_train.drop(['attack_category'], axis=1)\n",
    "y = ataques_train.attack_category.copy()\n",
    "X_test_40var = ataques_test.drop(['attack_category'], axis=1)\n",
    "y_test_40var = ataques_test.attack_category.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos desbalanceados\n",
    "# Extra Trees Classification - Esto toma mas de 40 minutos en mi Laptop\n",
    "# t0 = time()\n",
    "\n",
    "# num_trees = 500\n",
    "# max_features = 5\n",
    "# seed = 123\n",
    "# kfold = KFold(n_splits=5, random_state=seed)\n",
    "# model = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "# results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "# print(results.mean())\n",
    "# model.fit(X_train, y_train)\n",
    "# precision = model.score(X_test, y_test)\n",
    "# print(\"Puntaje: \",precision)\n",
    "\n",
    "# precision = model.score(X_test_40var,y_test_40var)\n",
    "# print(\"Precisión validación Extra Trees: \",precision)\n",
    "# y_pred_class = model.predict(X_test_40var)\n",
    "# cnf_matrix = confusion_matrix(y_test_40var, y_pred_class)\n",
    "# print(cnf_matrix)\n",
    "\n",
    "# print(\"Tiempo total: %.2fs\" % (time() - t0))\n",
    "\n",
    "# RESULTADO\n",
    "# Los resultados sin balanceo de los datos y sin eliminar los valores \"unknow\" \n",
    "# de juego de datos de validación; utilizando 500 arboles y max_features 5, son:\n",
    "# 0.9997802308\n",
    "# Puntaje:  0.999813952623\n",
    "# Precisión validación Extra Trees:  0.917837243472\n",
    "# [[222625     94    579      0      0      0]\n",
    "#  [    71  60290    229      1      2      0]\n",
    "#  [     3      5   2369      0      0      0]\n",
    "#  [     0   5801      1    190      1      0]\n",
    "#  [     0     36      0      3      0      0]\n",
    "#  [   315  17446    963      3      2      0]]\n",
    "# Tiempo total: 2435.66s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje:  0.999571312894\n",
      "Precisión validación Extra Trees:  0.980195005132\n",
      "[[222983     12    303      0      0]\n",
      " [    71  60232    286      1      3]\n",
      " [     3      4   2370      0      0]\n",
      " [     0   5064      4    923      2]\n",
      " [     0     31      0      5      3]]\n",
      "Tiempo total: 36.98s\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Classification\n",
    "t0 = time()\n",
    "\n",
    "num_trees = 100\n",
    "max_features = 10\n",
    "model = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "model.fit(X_train, y_train)\n",
    "precision = model.score(X_test, y_test)\n",
    "print(\"Puntaje: \",precision)\n",
    "precision = model.score(X_test_40var,y_test_40var)\n",
    "print(\"Precisión validación Extra Trees: \",precision)\n",
    "y_pred_class = model.predict(X_test_40var)\n",
    "cnf_matrix = confusion_matrix(y_test_40var, y_pred_class)\n",
    "print(cnf_matrix)\n",
    "\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.999698331296\n",
      "Score Validación AdaBoost:  0.979432090318\n",
      "[[223260      9     29      0      0]\n",
      " [    68  60287    236      0      2]\n",
      " [     3      0   2374      0      0]\n",
      " [     0   5628      0    362      3]\n",
      " [     0     32      0      2      5]]\n",
      "Tiempo total: 245.52s\n"
     ]
    }
   ],
   "source": [
    "# Utilizando AdaBoost\n",
    "t0 = time()\n",
    "\n",
    "# Crear y entrenar un Árbol de decisión con AdaBoost\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=15), n_estimators=100) # algorithm=\"SAMME\", algorithm=\"SAMME.R\", learning_rate=1.0\n",
    "\n",
    "bdt.fit(X_train, y_train)\n",
    "y_pred = bdt.predict(X_test)\n",
    "precision = bdt.score(X_test, y_test)\n",
    "print(\"Score: \",precision)\n",
    "precision = bdt.score(X_test_40var, y_test_40var)\n",
    "print(\"Score Validación AdaBoost: \",precision)\n",
    "\n",
    "y_pred_class = bdt.predict(X_test_40var)\n",
    "cnf_matrix = confusion_matrix(y_test_40var, y_pred_class) # Matríz de correlación\n",
    "print(cnf_matrix)\n",
    "\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 99.96%\n",
      "Precisión con XGBoost: 98.03%\n",
      "[[223227     21     50      0      0]\n",
      " [    71  60267    250      2      3]\n",
      " [     4      0   2373      0      0]\n",
      " [     0   5316      3    670      4]\n",
      " [     0     27      0      5      7]]\n",
      "Tiempo total: 681.87s\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "t0 = time()\n",
    "\n",
    "model = XGBClassifier(booster=\"gbtree\", max_depth=15, n_estimators=100, n_jobs=-1, random_state=1234, silent=True)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "y_pred = model.predict(X_test_40var)\n",
    "accuracy = accuracy_score(y_test_40var, y_pred)\n",
    "print(\"Precisión con XGBoost: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test_40var, y_pred) # Matríz de correlación\n",
    "print(cnf_matrix)\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensamble (Voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.999380785291\n",
      "Precisión con Voting (DT , KNN):  0.975005131714\n",
      "[[222332     32    934      0      0]\n",
      " [    72  59891    618      7      5]\n",
      " [     6      3   2368      0      0]\n",
      " [    23   5494     71    398      7]\n",
      " [     0     27      3      4      5]]\n",
      "Tiempo total: 282.85s\n"
     ]
    }
   ],
   "source": [
    "# Training classifiers\n",
    "t0 = time()\n",
    "clf1 = DecisionTreeClassifier(max_depth=15)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=5)\n",
    "#clf3 = SVC(kernel='rbf') # probability=True\n",
    "#eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)], voting='soft', weights=[2,1,2])\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2)], voting='soft', weights=[2,1])\n",
    "\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "#clf3 = clf3.fit(X_train, y_train) # Este clasificador toma demasiado tiempo\n",
    "\n",
    "eclf = eclf.fit(X_train, y_train)\n",
    "precision = eclf.score(X_test, y_test)\n",
    "print(\"Precisión: \",precision)\n",
    "\n",
    "# Validamos los datos de prueba\n",
    "precision = eclf.score(X_test_40var, y_test_40var)\n",
    "print(\"Precisión con Voting (DT , KNN): \",precision)\n",
    "y_pred_class = eclf.predict(X_test_40var)\n",
    "cnf_matrix = confusion_matrix(y_test_40var, y_pred_class)\n",
    "print(cnf_matrix)\n",
    "\n",
    "print(\"Tiempo total: %.2fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen de los métodos utilizados\n",
    "\n",
    "| MODELO                                                 \t\t   | Puntaje | \n",
    "| --- | --- |\n",
    "| 1. Extra Trees Classification (datos desbalanceados)             | 91.78% |\n",
    "| 2. Extra Trees Classification                                    | 98.02% |\n",
    "| 3. AdaBoost                                                      | 97.94% |\n",
    "| 4. XGBoost                                                       | 98.03% |\n",
    "| 5. Ensamble (Voting - DT, KNN)                                    | 97.50% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede observarse el mejoramiento de los datos de entrenamiento, realza la precisión en la mayoría de los modelos. Se observa que todos tienen una precisión muy similar, debido a que estamos utilizando casi los mismos metodos, de la forma como el ganador utilizó en su momento (_arboles de decision con bagging y boosting_).\n",
    "\n",
    "Aunque XGBoost y ExtraTrees tiene casi la misma precisión, este último es más eficiente a la hora de procesar los datos presentados, tomando menos tiempo en ofrecer los resultados.\n",
    "\n",
    "Estas precisiones podrian mejorarse pero como esto es solo un ejercicio académico y no amerita gastar mas tiempo habiendo superado la precisión del ganador, dejaré hasta aquí los analísis. Si desean ver otros modelos aplicados como redes neuronales o Deep learning pueden revisar la carpeta del github donde estan todos los procesos documentados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de resultados con el ganador del KDDCup\n",
    "\n",
    "Cabe notar que aquí se supera la precisión del ganador por que en su tiempo, no se tenia mucho conocimiento de los datos con errores y el tiempo de la competencia tampoco daba para mejorar los datos. De igual manera, los algoritmos y los dispositivos de procesamiento de la fecha del concurso 1999 no eran tan robustos como lo son hoy en día.\n",
    "\n",
    "Aqui comparamos las matrices del ganador con las del mejor modelo hallado (XGBoost) anteriormente:\n",
    "\n",
    "**Extra Trees Classification: ** _Tiempo total: 36.98s , precisión: 0.980195005132_\n",
    "\n",
    "|predicted | dos |  normal | probe  |  r2l  |   u2r  |\n",
    "|--- | --- | --- | --- | --- | --- |\n",
    "|**dos**| **222983**   |  12  |  303   |   0   |   0|\n",
    "|**normal**|    71  | **60232**  |  286  |   1  |   3|\n",
    "|**probe**|  3    |  4   | **2370**  |   0   |   0|\n",
    "|**r2l**|  0  | 5064   |   4  |  **923**      2|\n",
    "|**u2r**|  0  |   31   |   0  |    5   |   **3**|\n",
    "\n",
    "\n",
    "**XGBoost: ** _Tiempo total: 681.87s, precisión: 0.98030790283954838_\n",
    "\n",
    "|predicted | dos |  normal | probe  |  r2l  |   u2r  |\n",
    "|--- | --- | --- | --- | --- | --- |\n",
    "|**dos**| **223227**  |   21  |   50   |   0   |   0|\n",
    "|**normal**| 71 | **60267**  |  250  |    2   |   3|\n",
    "|**probe**| 4   |   0  | **2373**   |   0   |   0|\n",
    "|**r2l**| 0   | 5316   |   3   | **670**   |   4|\n",
    "|**u2r**| 0   |  27    |  0    |  5    |  **7**|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PERFORMANCE OF THE WINNING ENTRY\n",
    "\n",
    "The winning entry achieved an average cost of 0.2331 per test example and obtained the following confusion matrix:\n",
    "\n",
    "|predicted | 0 |  1 | 2  |  3   |   4   |  correct |\n",
    "|---    | --- | --- | --- | --- | --- | --- |\n",
    "|0         |   60262 |  243  |  78   |   4 |     6   |    99.5% |\n",
    "|1         |     511 |  3471 |   184 |   0 |     0   |    83.3% |\n",
    "|2         |    5299 |  1328 | 223226|   0 |     0   |    97.1% |\n",
    "|3         |     168 |    20 |     0 |  30 |    10   |    13.2% |\n",
    "|4         |   14527 |   294 |     0 |   8 |  1360   |     8.4% |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| correct  | 74.6% | 64.8% | 99.9% | 71.4% | 98.8% | --- |\n",
    "\n",
    "In the table above the five attack categories are numbered as follows:\n",
    "\n",
    "|código| tipo de ataque |\n",
    "|---| --- |\n",
    "|0 |\tnormal                  |\n",
    "|1 |\tprobe                   |\n",
    "|2 |\tdenial of service (DOS) |\n",
    "|3 |\tuser-to-root (U2R)      |\n",
    "|4 |\tremote-to-local (R2L)   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí mismo puede encontrar una solución del ejercicio pero utilizando el lenguaje R. [ver archivo en R](Solucion_egiron.R)\n",
    "\n",
    "``` R\n",
    "# Detección de Intrusos en Redes LAN\n",
    "# Solución Trabajo final Diplomado Data Mining Univalle 2017\n",
    "# Author: Ernesto Girón E. - e.giron.e at gmail\n",
    "# Nov 21, 2017\n",
    "\n",
    "## DETECCIÓN DE INTRUSOS EN REDES\n",
    "\n",
    "# Estos datos fueron usados para la edición de 1999 del KDD cup. \n",
    "# Los datos fueron generados por Lincoln Labs: Nueve semanas de registro de paquetes \n",
    "# TCP fueron recolectadas para una red LAN de una oficina de las fuerzas aéreas de USA.\n",
    "# Durante el uso de la LAN, _varios ataques_ fueron ejecutados por el personal. \n",
    "# El paquete crudo fue agregado junto con la información de la conexión. \n",
    "# \n",
    "# Para cada registro, algunas características extra fueron derivadas, basados en \n",
    "# conocimiento del dominio sobre ataques a redes; hay 38 tipos diferentes de ataques, \n",
    "# pertenecientes a 4 categorías principales. Algunos tipos de ataque aparecen solo en \n",
    "# los datos de prueba(test data), y las frecuencias de los tipo de ataque en los \n",
    "# conjuntos de entrenamiento y prueba no son las mismas(para hacerlo más realista). \n",
    "# Información adicional sobre los datos puede ser encontrada \n",
    "# en (http://kdd.ics.uci.edu/databases/kddcup99/task.html) y los resumenes de los \n",
    "# resultados de la competencia KDD cup (http://cseweb.ucsd.edu/~elkan/clresults.html). \n",
    "# En la última página también se indica que hay una matriz de costo asociada con las \n",
    "# equivocaciones.  El ganador de la competencia usó árboles de decisión C5 en combinación \n",
    "# con boosting y bagging.\n",
    "# \n",
    "# **Referencias**:\n",
    "#   - PNrule: _A New Framework for Learning Classifier Models in Data Mining \n",
    "#    (A Case-Study in Network Intrusion Detection) (2000) by R. Agarwal and \n",
    "#    M. V. Joshi_. This paper proposes a new, very simple rule learning algorithm, \n",
    "#    and tests it on the network intrusion dataset. In the first stage, rules are \n",
    "#    learned to identify the target class, and then in the second stage, rules are \n",
    "#    learned to identify cases that were incorrectly classified as positive \n",
    "#    according to the first rules.\n",
    "\n",
    "# Pasos solución 1\n",
    "# \n",
    "# 1. Cargar las librerías a utilizar\n",
    "# 2. Cargar los datos e importarlos a un dataframe\n",
    "# 3. Visualizar los datos\n",
    "# 4. Limpiar y transformar los datos\n",
    "# 5. Códificar los datos\n",
    "# 6. Seleccionar los parámetros más importantes\n",
    "# 7. Separando el conjunto de datos de entrenamiento y de validación\n",
    "# 8. Selección de algoritmos y métodos\n",
    "# 9. Resumen de los métodos utilizados\n",
    "# 10. Comparación de resultados con el ganador del KDDCup\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Cargar las librerías a utilizar\n",
    "# ---------------------------------------------------------\n",
    "# Instalar las librerias si no las han descargado\n",
    "# install.packages(\"dplyr\")\n",
    "# install.packages(\"dummies\")\n",
    "# install.packages(\"mlr\")\n",
    "# install.packages(\"reshape\")\n",
    "# install.packages(\"Hmisc\")\n",
    "# install.packages(\"corrplot\")\n",
    "# install.packages(\"tree\")\n",
    "# install.packages(\"party\")\n",
    "# install.packages(\"partykit\")\n",
    "# install.packages(\"randomForest\")\n",
    "# install.packages(\"e1071\")\n",
    "# install.packages(\"gbm\")\n",
    "# install.packages(\"caret\")\n",
    "# install.packages(\"ranger\")\n",
    "\n",
    "# llamado a las librerías\n",
    "library(\"dplyr\")\n",
    "library(\"plyr\")\n",
    "library(\"dummies\")\n",
    "# library(\"mlr\")\n",
    "library(\"ggplot2\")\n",
    "library(\"reshape\")\n",
    "library(\"leaps\")\n",
    "library(\"Hmisc\")\n",
    "library(\"corrplot\")\n",
    "library(\"RColorBrewer\")\n",
    "library(\"tree\")\n",
    "library(\"party\")\n",
    "library(\"rpart\")\n",
    "library(\"partykit\")\n",
    "library(\"randomForest\")\n",
    "library(\"ranger\")\n",
    "library(\"e1071\")\n",
    "library(\"gbm\")\n",
    "library(\"caret\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Cargar los datos e importarlos a un dataframe\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Definimos el directorio de trabajo\n",
    "# setwd(\"C:/Users/Invitado/Desktop/egiron/Trabajo\")  # Path PC No. 30 Univalle\n",
    "# setwd(\"~/Desktop/DiplomadoUnivalle_DS2017/statistical_learning/ISLR/Ejercicios\")\n",
    "\n",
    "# Cargamos los datos de entrenamiento y validacón\n",
    "# data_10_percent_train <- read.csv(file.choose())\n",
    "data_10_percent_train <- read.csv(\"data/kddcup.data_10_percent\", stringsAsFactors=FALSE, header = FALSE, sep = ',', dec = '.')\n",
    "data_10_percent_test <- read.csv(\"data/corrected\", stringsAsFactors=FALSE, header = FALSE, sep = ',', dec = '.')\n",
    "\n",
    "# Asignar los nombres a las columnas\n",
    "nomcols <- c(\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \n",
    "             \"dst_bytes\", \"land\", \"wrong_fragment\", \n",
    "             \"urgent\", \"hot\", \"num_failed_logins\", \n",
    "             \"logged_in\", \"num_compromised\", \"root_shell\",\n",
    "             \"su_attempted\", \"num_root\", \"num_file_creations\", \n",
    "             \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n",
    "             \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\",\n",
    "             \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \n",
    "             \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\", \n",
    "             \"dst_host_count\", \"dst_host_srv_count\", \"dst_host_same_srv_rate\",\n",
    "             \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\", \n",
    "             \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\",\n",
    "             \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \n",
    "             \"dst_host_srv_rerror_rate\", \"attack_type\")\n",
    "\n",
    "# Asignar los nombres a las columnas a cada conjunto de datos\n",
    "colnames(data_10_percent_train) <- nomcols\n",
    "colnames(data_10_percent_test) <- nomcols\n",
    "\n",
    "# Cantidad de observaciones y de variables\n",
    "dim(data_10_percent_train)\n",
    "dim(data_10_percent_test)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Visualizar los datos\n",
    "# ---------------------------------------------------------\n",
    "View(data_10_percent_train) # Despliegue la tabla completa\n",
    "# View(data_10_percent_test)\n",
    "\n",
    "head(data_10_percent_train, n=3) # Muestre las primeras 3 observaciones\n",
    "tail(data_10_percent_train, n=3) # Muestre las últimas 3 observaciones\n",
    "\n",
    "summary(data_10_percent_train) # Muestre un resumen de los datos\n",
    "#summary(data_10_percent_test)\n",
    "\n",
    "# Visualizamos la estructura de los datos, el tipo de dato o clase de cada predictor\n",
    "str(data_10_percent_train)\n",
    "#str(data_10_percent_test)\n",
    "\n",
    "# Visualizamos los tipos de ataques y su frecuencia.\n",
    "unique(data_10_percent_train$attack_type) # Valores unicos de tipos de ataque\n",
    "unique(data_10_percent_test$attack_type) # Valores unicos de tipos de ataque\n",
    "\n",
    "# Convertimos los valores a factores para hacer operaciónes con ellos\n",
    "tipos_ataque = as.factor(data_10_percent_train$attack_type)\n",
    "levels(tipos_ataque)\n",
    "# typeof(tipos_ataque)\n",
    "summary(tipos_ataque) # Visualizamos la cantidad de intrusos por tipo de ataque\n",
    "\n",
    "# Graficamos rápidamente estos datos\n",
    "par(mfrow=c(1,1))\n",
    "plot(tipos_ataque,xlab=\"Tipos de Ataques\",ylab=\"Cantidad de ataques\", \n",
    "     main=\"Cantidad de Intrusos por Tipo de Ataque\", las=2, col=\"red\", \n",
    "     cex.main=1.5, cex.lab=1.2, cex.axis=0.6, cex.sub=1.2) # font =2, family = 'Arial'\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Limpiar y transformar los datos\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Reemplazamos el punto '.' final en los valores de la variable tipo de ataque (attack_type)\n",
    "data_10_percent_train$attack_type <- gsub(\".\", \"\", data_10_percent_train$attack_type, fixed = TRUE)\n",
    "data_10_percent_test$attack_type <- gsub(\".\", \"\", data_10_percent_test$attack_type, fixed = TRUE)\n",
    "# View(data_10_percent_train)\n",
    "# summary(as.factor(data_10_percent_train$attack_type))\n",
    "\n",
    "# Gráficamos de nuevo\n",
    "tipos_ataque_train = factor(data_10_percent_train$attack_type, ordered = TRUE)\n",
    "tipos_ataque_test = as.factor(data_10_percent_test$attack_type)\n",
    "levels(tipos_ataque_train)\n",
    "levels(tipos_ataque_test)\n",
    "\n",
    "par(mfrow=c(2,1))\n",
    "plot(tipos_ataque_train, ylab=\"Cantidad de ataques\", \n",
    "     main=\"Cantidad de Intrusos por Tipo de Ataque\", las=2, col=\"red\", \n",
    "     cex.main=1.5, cex.lab=1.2, cex.axis=0.6, cex.sub=1.2) # font=2, family = 'Arial'\n",
    "\n",
    "plot(tipos_ataque_test,xlab=\"Tipos de Ataques\",ylab=\"Cantidad de ataques\", \n",
    "     las=2, col=\"red\", cex.main=1.5, cex.lab=1.2, cex.axis=0.6, cex.sub=1.2) # font=2, family = 'Arial'\n",
    "\n",
    "# Como se puede observar la cantidad de tipos de ataques en los datos de entrenamiento\n",
    "# y los datos de validación son diferentes como se menciona en la literatura o página web del concurso\n",
    "\n",
    "# Revisamos valores faltantes o nulos en los dos juegos de datos\n",
    "sum(is.na.data.frame(data_10_percent_train))\n",
    "sum(is.na.data.frame(data_10_percent_test))\n",
    "\n",
    "# Eliminamos duplicados\n",
    "# Existen varias formas de eliminar las observaciones duplicadas\n",
    "# Utilizando, las funciones duplicated, unique o la librería dplyr\n",
    "# data_10_percent_train<-data_10_percent_train[duplicated(data_10_percent_train),]\n",
    "\n",
    "# Si desea ver cuales son los valores duplicados\n",
    "#data_10_percent_train[duplicated(data_10_percent_train),]\n",
    "\n",
    "# La función duplicated solo devuelve los indices donde se encuentran los valores duplicados\n",
    "# Por lo que es necesario combinarla con otras operaciones así:\n",
    "data_10_percent_train<-data_10_percent_train[!duplicated(data_10_percent_train), ]\n",
    "dim(data_10_percent_train)\n",
    "\n",
    "# Creamos un nuevo conjunto de datos o dataset con los datos no duplicados de Validación\n",
    "# Esto con el fin de que nuestros modelos sean mas eficientes, pero dejando los datos de \n",
    "# Validación originales por que son los que nos permiten comparar al final con los \n",
    "# resultados del ganador del concurso\n",
    "data_10_percent_test_small<-data_10_percent_test[duplicated(data_10_percent_test),]\n",
    "dim(data_10_percent_test)\n",
    "dim(data_10_percent_test_small)\n",
    "\n",
    "# La otra forma de hacerlo\n",
    "# unique(data_10_percent_train) Remueve duplicados en un solo comando\n",
    "\n",
    "# Una forma mas eficiente de hacerlo en lugar de unique() es utilizando la libreria dplyr\n",
    "# Remueve los valores duplicados basandose en todas las columnas\n",
    "#distinct(data_10_percent_train)\n",
    "#dim(data_10_percent_train)\n",
    "\n",
    "# Si desea cambiar un valor específico manualmente\n",
    "#data_10_percent_train_corregido <- edit(data_10_percent_train)\n",
    "#fix(data_10_percent_train) # equivalente a anterior\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. Códificar los datos\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Como se observó anteriormente hay 4 variables categóricas incluyendo la independiente\n",
    "# para lo cual debemos de modificar con el fin de que los algortimos entiendan y se pueda\n",
    "# trabajar con ellas. Es mas eficiente para un computador entender números.\n",
    "\n",
    "# Dicho lo anterior empezamos categorizando nuestros ataques en 4 categorias que especifican en el concurso\n",
    "# Fuente: http://kdd.ics.uci.edu/databases/kddcup99/training_attack_types\n",
    "\n",
    "data_10_percent_train$attack_category <- data_10_percent_train$attack_type\n",
    "data_10_percent_test$attack_category <- data_10_percent_test$attack_type\n",
    "data_10_percent_test_small$attack_category <- data_10_percent_test_small$attack_type\n",
    "#dim(data_10_percent_train)\n",
    "\n",
    "ataques_tipo = c('normal','buffer_overflow','loadmodule','perl','rootkit','back','neptune',\n",
    "                 'smurf','pod','teardrop','land','guess_passwd','ftp_write','imap',\n",
    "                 'phf','multihop','warezmaster','warezclient','spy','portsweep',\n",
    "                 'ipsweep','satan','nmap','snmpgetattack', 'named', 'xlock', \n",
    "                 'xsnoop', 'sendmail', 'saint','apache2', 'udpstorm','xterm', \n",
    "                 'mscan', 'processtable', 'ps','httptunnel', 'worm', 'mailbomb',\n",
    "                 'sqlattack', 'snmpguess')\n",
    "\n",
    "ataques_ctg = c('normal','u2r','u2r','u2r','u2r','dos','dos','dos','dos','dos','dos',\n",
    "                'r2l','r2l','r2l','r2l','r2l','r2l','r2l','r2l','probe','probe',\n",
    "                'probe','probe','unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
    "                'unknown','unknown', 'unknown','unknown', 'unknown', 'unknown', \n",
    "                'unknown','unknown', 'unknown', 'unknown','unknown', 'unknown')\n",
    "\n",
    "data_10_percent_train$attack_category <- mapvalues(data_10_percent_train$attack_category, \n",
    "                                                   from=ataques_tipo, \n",
    "                                                   to=ataques_ctg)\n",
    "\n",
    "data_10_percent_test$attack_category <- mapvalues(data_10_percent_test$attack_category, \n",
    "                                                  from=ataques_tipo, \n",
    "                                                  to=ataques_ctg)\n",
    "\n",
    "data_10_percent_test_small$attack_category <- mapvalues(data_10_percent_test_small$attack_category, \n",
    "                                                        from=ataques_tipo, \n",
    "                                                        to=ataques_ctg)\n",
    "# Vefificamos los nuevos datos\n",
    "summary(as.factor(data_10_percent_train$attack_category))\n",
    "# View(data_10_percent_train)\n",
    "\n",
    "# Graficamos\n",
    "par(mfrow=c(1,1))\n",
    "categoria_ataques = as.factor(data_10_percent_train$attack_category)\n",
    "plot(categoria_ataques,xlab=\"Categorias de Tipos de Ataque\",ylab=\"Cantidad de ataques\", \n",
    "     main=\"Cantidad de Intrusos \\npor Categorias de Ataque\", las=2, col=\"red\", \n",
    "     cex.main=1.5, cex.lab=1.2, cex.axis=0.6, cex.sub=1.2)\n",
    "\n",
    "# Podriamos re-categorizar entre intrusos y no intrusos, buenas o malas conexiones, 0 o 1\n",
    "# De tal forma que tengamos una variable independiente binaria y sea mas facil llevar a cabo\n",
    "# las predicciones.\n",
    "\n",
    "# Ahora procedemos a crear nuestras variables dummy, debido a que los predictores \n",
    "# categóricos que tenemos contienen mas de 2 valores nominales y no ordenados. \n",
    "# Esto significa que no podemos utilizar la función factor, usaremos una librería \n",
    "# llamada dummies que hace esto por nosotros:\n",
    "# dummy(data_10_percent_train$protocol_type, sep = \"_\")\n",
    "\n",
    "variables_categoricas = c('protocol_type', 'service', 'flag')\n",
    "#data_10_percent_train <- cbind(data_10_percent_train, dummy(data_10_percent_train$service, sep = \"_service_\"))\n",
    "\n",
    "data_10_percent_train_dummies <- dummy.data.frame( data_10_percent_train, sep = \"_\", all=FALSE )\n",
    "protocol_type_dummy = get.dummy( data_10_percent_train_dummies, 'protocol_type' )\n",
    "service_dummy = get.dummy( data_10_percent_train_dummies, 'service' )\n",
    "flag_dummy = get.dummy( data_10_percent_train_dummies, 'flag' )\n",
    "data_10_percent_train <- cbind(data_10_percent_train, protocol_type_dummy, service_dummy, flag_dummy)\n",
    "dim(data_10_percent_train) # Verificamos las nuevas dimensiones de nuestros datos\n",
    "names(data_10_percent_train)\n",
    "\n",
    "data_10_percent_test_dummies <- dummy.data.frame( data_10_percent_test, sep = \"_\", all=FALSE )\n",
    "protocol_type_dummy = get.dummy( data_10_percent_test_dummies, 'protocol_type' )\n",
    "service_dummy = get.dummy( data_10_percent_test_dummies, 'service' )\n",
    "flag_dummy = get.dummy( data_10_percent_test_dummies, 'flag' )\n",
    "data_10_percent_test <- cbind(data_10_percent_test, protocol_type_dummy, service_dummy, flag_dummy)\n",
    "dim(data_10_percent_test) # Verificamos las nuevas dimensiones de nuestros datos\n",
    "#names(data_10_percent_train)\n",
    "\n",
    "data_10_percent_testsmall_dummies <- dummy.data.frame( data_10_percent_test_small, sep = \"_\", all=FALSE )\n",
    "protocol_type_dummy = get.dummy( data_10_percent_testsmall_dummies, 'protocol_type' )\n",
    "service_dummy = get.dummy( data_10_percent_testsmall_dummies, 'service' )\n",
    "flag_dummy = get.dummy( data_10_percent_testsmall_dummies, 'flag' )\n",
    "data_10_percent_test_small <- cbind(data_10_percent_test_small, protocol_type_dummy, service_dummy, flag_dummy)\n",
    "dim(data_10_percent_test_small)\n",
    "\n",
    "# de igual forma el paquete \"mlr\" inluye la funcion createDummyFeatures para este proposito:\n",
    "# data_10_percent_train_dummies <- createDummyFeatures(data_10_percent_train, cols = 'protocol_type')\n",
    "\n",
    "# Ahora eliminamos las variables categóricas para que solo quede una matríz de números a análizar\n",
    "data_10_percent_train <- data_10_percent_train[, !(names(data_10_percent_train) %in% variables_categoricas)]\n",
    "data_10_percent_test <- data_10_percent_test[, !(names(data_10_percent_test) %in% variables_categoricas)]\n",
    "data_10_percent_test_small <- data_10_percent_test_small[, !(names(data_10_percent_test_small) %in% variables_categoricas)]\n",
    "# dim(data_10_percent_train)\n",
    "# dim(data_10_percent_test)\n",
    "# dim(data_10_percent_test_small)\n",
    "\n",
    "# Separamos los datos de la variable independiente para luego utilizarlos como textos\n",
    "# Y luego la convertimos a números para computarla en los siguientes análisis\n",
    "y_train <- data_10_percent_train$attack_category\n",
    "data_10_percent_train$attack_type <- NULL\n",
    "data_10_percent_train$attack_category <- as.factor(data_10_percent_train$attack_category)\n",
    "dim(data_10_percent_train)\n",
    "y_test <- data_10_percent_test$attack_category\n",
    "data_10_percent_test$attack_type <- NULL\n",
    "data_10_percent_test$attack_category <- as.factor(data_10_percent_test$attack_category)\n",
    "y_test_small <- data_10_percent_test_small$attack_category\n",
    "data_10_percent_test_small$attack_type <- NULL\n",
    "data_10_percent_test_small$attack_category <- as.factor(data_10_percent_test_small$attack_category)\n",
    "# \n",
    "# # Comprobamos que todas las variables son númericas\n",
    "str(data_10_percent_train)\n",
    "\n",
    "# Liberamos un poco de memoria, removiendo objetos que no necesitamos\n",
    "rm(data_10_percent_train_dummies, data_10_percent_test_dummies, data_10_percent_testsmall_dummies)\n",
    "rm(flag_dummy, protocol_type_dummy, service_dummy)\n",
    "rm(tipos_ataque, tipos_ataque_test, tipos_ataque_train, ataques_ctg, ataques_tipo)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 6. Seleccionar los parámetros más importantes\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Para seleccionar las mejores variables podemos hacerlo manual revisando una matríz \n",
    "# de correlaciones entre las variables y bajo el conocimiento de la lógica del negocio.\n",
    "\n",
    "data_10_percent_train_scaled <- data_10_percent_train\n",
    "data_10_percent_train_scaled$attack_category <- NULL\n",
    "data_10_percent_train_scaled = scale(data_10_percent_train_scaled)\n",
    "corr_train <- cor(data_10_percent_train_scaled)\n",
    "corr_train\n",
    "\n",
    "# Gráficamos la matríz\n",
    "# https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html\n",
    "# corrplot(corr_train, method=\"number\")\n",
    "melted_cormat <- melt(corr_train)\n",
    "# ggplot(melted_cormat, aes(X1, X2, fill = value)) + geom_tile() + \n",
    "#   scale_fill_gradient(low = \"white\",  high = \"red\")\n",
    "\n",
    "# http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization\n",
    "# http://www.sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software\n",
    "# http://www.sthda.com/english/wiki/visualize-correlation-matrix-using-correlogram\n",
    "ggplot(data = melted_cormat, aes(X1, X2, fill = value))+ geom_tile(color = \"white\") + \n",
    "  scale_fill_gradient2(low = \"blue\", high = \"red\", mid = \"white\", midpoint = 0, \n",
    "                       limit = c(-1,1), space = \"Lab\",  name=\"Correlación de\\nPearson\") + \n",
    "  theme_minimal() + theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) + \n",
    "  coord_fixed()\n",
    "\n",
    "# Otra forma de ver las correlaciones junto con los p-values\n",
    "corr_train_2 <- rcorr(as.matrix(data_10_percent_train_scaled))\n",
    "corr_train_2\n",
    "# Extraer valores\n",
    "corr_train_2$r # Extraer los coeficientes de correlación\n",
    "corr_train_2$P # Extraer p-values\n",
    "\n",
    "# ++++++++++++++++++++++++++++\n",
    "# flattenCorrMatrix\n",
    "# ++++++++++++++++++++++++++++\n",
    "# cormat : matrix of the correlation coefficients\n",
    "# pmat : matrix of the correlation p-values\n",
    "flattenCorrMatrix <- function(cormat, pmat) {\n",
    "  ut <- upper.tri(cormat)\n",
    "  data.frame(\n",
    "    row = rownames(cormat)[row(cormat)[ut]],\n",
    "    column = rownames(cormat)[col(cormat)[ut]],\n",
    "    cor  =(cormat)[ut],\n",
    "    p = pmat[ut]\n",
    "  )\n",
    "}\n",
    "\n",
    "# Visualizar la matríz de otra forma\n",
    "flattenCorrMatrix(corr_train_2$r, corr_train_2$P)\n",
    "\n",
    "# Liberamos memoria\n",
    "rm(data_10_percent_train_scaled, corr_train, melted_cormat, corr_train_2)\n",
    "\n",
    "# Ahora lo hacemos de forma automática, este metodo es para obtener la \n",
    "# mejor selección de predictores por lo que tomará algo de tiempo\n",
    "# Este procedimiento toma demasiado tiempo por el numero de registros y variables \n",
    "# por lo que esta comentado\n",
    "# regfit=regsubsets(data_10_percent_train$attack_category~.,data_10_percent_train, \n",
    "#                   really.big=T, nvmax=20)\n",
    "# summary(regfit)\n",
    "# reg.summary=summary(regfit)\n",
    "# names(reg.summary)\n",
    "# reg.summary$rsq\n",
    "\n",
    "# Gráficamos para visualmente ver la importancia de las variables\n",
    "# par(mfrow=c(2,2))\n",
    "# plot(reg.summary$rss,xlab=\"Número de Variables\",ylab=\"RSS\",type=\"l\")\n",
    "# plot(reg.summary$adjr2,xlab=\"Número de Variables\",ylab=\"R^2 Ajustado\",type=\"l\")\n",
    "# which.max(reg.summary$adjr2)\n",
    "# points(11,reg.summary$adjr2[11], col=\"red\",cex=2,pch=20)\n",
    "# plot(reg.summary$cp,xlab=\"Número de Variables\",ylab=\"Cp\",type='l')\n",
    "# which.min(reg.summary$cp)\n",
    "# points(10,reg.summary$cp[10],col=\"red\",cex=2,pch=20)\n",
    "# which.min(reg.summary$bic)\n",
    "# plot(reg.summary$bic,xlab=\"Número de Variables\",ylab=\"BIC\",type='l')\n",
    "# points(6,reg.summary$bic[6],col=\"red\",cex=2,pch=20)\n",
    "# plot(regfit.full,scale=\"r2\")\n",
    "# plot(regfit.full,scale=\"adjr2\")\n",
    "# plot(regfit.full,scale=\"Cp\")\n",
    "# plot(regfit.full,scale=\"bic\")\n",
    "# coef(regfit.full,6)\n",
    "\n",
    "\n",
    "# Como los procesos o metodos anteriores toman demasiado tiempo tomamos las 40 variables\n",
    "# más importantes obtenidas del ejercicio ya resulto con python localizado en\n",
    "# https://github.com/egiron/DataScience/blob/master/EjerciciosTmp/Deteccion%20intrusos%20redes.ipynb\n",
    "predictores = c('same_srv_rate', 'flag_SF', 'dst_host_same_srv_rate', 'service_private',\n",
    "                 'dst_host_srv_serror_rate', 'service_http', 'logged_in',\n",
    "                 'dst_host_srv_count', 'count', 'srv_serror_rate', 'flag_S0',\n",
    "                 'dst_host_serror_rate', 'dst_host_count', 'rerror_rate', 'serror_rate',\n",
    "                 'dst_host_rerror_rate', 'src_bytes', 'srv_rerror_rate',\n",
    "                 'dst_host_same_src_port_rate', 'dst_host_srv_rerror_rate',\n",
    "                 'protocol_type_udp', 'service_ecr_i', 'flag_REJ', 'service_pop_3',\n",
    "                 'protocol_type_tcp', 'diff_srv_rate', 'hot', 'dst_host_diff_srv_rate',\n",
    "                 'service_telnet', 'service_domain_u', 'wrong_fragment',\n",
    "                 'dst_host_srv_diff_host_rate', 'num_compromised', 'service_smtp',\n",
    "                 'srv_count', 'dst_bytes', 'srv_diff_host_rate', 'service_ftp_data',\n",
    "                 'duration', 'service_ftp', 'attack_category')\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 7. Separando el conjunto de datos de entrenamiento y de validación\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "X <- data_10_percent_train[,predictores]\n",
    "\n",
    "# En este paso deberiamos de balancear la muestra o datos de entrenamiento \n",
    "# para obtener mejores resultados en nuestros clasificadores del paso sgte.\n",
    "# Pero continuaremos adelante con el ejercicio y luego retomaremos este paso utilizando\n",
    "# el conjunto de datos completo y no solo el del 10% de entrenamiento.\n",
    "\n",
    "# set.seed(12345)\n",
    "# data_10_percent_train_dos <- data_10_percent_train[data_10_percent_train$attack_type == 'dos',] #Sacamos solo los ejemplos tipo dos\n",
    "# data_10_percent_train_normal <- data_10_percent_train[data_10_percent_train$attack_type == 'normal',] #Sacamos solo los ejemplos tipo normal.\n",
    "# data_10_percent_train_probe <- data_10_percent_train[data_10_percent_train$attack_type == 'probe',] #Sacamos solo los ejemplos tipo probe\n",
    "# data_10_percent_train_r2l <- data_10_percent_train[data_10_percent_train$attack_type == 'r2l',] #Sacamos solo los ejemplos tipo r2l\n",
    "# data_10_percent_train_u2r <- data_10_percent_train[data_10_percent_train$attack_type == 'u2r',] #Sacamos solo los ejemplos tipo u2r\n",
    "# \n",
    "# data_10_percent_train_dos <- data_10_percent_train_dos[sample(nrow(dos), 100000), ]# Tomamos 100.000 ejemplos aleatoriamente sin reemplazo. Podemos quitar muchos mas si queremos!!!!\n",
    "# data_10_percent_train_normal <- data_10_percent_train_normal[sample(nrow(normal), 10000),]# Tomamos 10.000 ejemplos aleatoriamente sin reemplazo\n",
    "# \n",
    "# # Ahora unimos las partes en un solo dataframe\n",
    "# data_10_percent_train_balanced <- rbind(data_10_percent_train_dos, data_10_percent_train_normal,\n",
    "#                  data_10_percent_train_probe, data_10_percent_train_r2l, \n",
    "#                  data_10_percent_train_u2r)\n",
    "\n",
    "\n",
    "set.seed(1234)\n",
    "ind <- sample(2, nrow(X), replace=TRUE, prob=c(0.7, 0.3))\n",
    "Xr <- X[ind==1,]\n",
    "yr <- Xr$attack_category\n",
    "Xt <- X[ind==2,]\n",
    "yt <- Xt$attack_category\n",
    "rm(ind) # Liberamos memoria\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 8. Selección de algoritmos y métodos\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Iniciamos con un Árbol de decisión simple\n",
    "tree.intrusos=tree(Xr$attack_category~.,Xr)\n",
    "summary(tree.intrusos)\n",
    "plot(tree.intrusos, cex=.75)\n",
    "text(tree.intrusos,pretty=0)\n",
    "tree.intrusos\n",
    "\n",
    "# Otra forma de crearlos utilizando la librería party\n",
    "tree.intrusos2 <- ctree(Xr$attack_category~. , data=Xr)\n",
    "# Visualizar la matríz de confusión sobre los datos de validación\n",
    "yt_pred2 = predict(tree.intrusos2, Xt, type=\"response\") \n",
    "table(yt_pred2, Xt$attack_category) # yt\n",
    "# Sin poda\n",
    "plot(tree.intrusos2, type=\"simple\")\n",
    "text(tree.intrusos2)\n",
    "\n",
    "# Transformemos las salidas de probabilidad a salidas categoricas\n",
    "# maxidx <- function(arr) {\n",
    "#   return(which(arr == max(arr)))\n",
    "# }\n",
    "# idx <- apply(yt_pred2, c(1), maxidx)\n",
    "# prediction <- c('dos', 'normal', 'probe', 'r2l', 'u2r', 'unknown')[idx]\n",
    "# table(prediction, Xt$attack_category)\n",
    "\n",
    "# Como se observa anteriormente utilizamos un árbol de regresion por lo que la variable independiente era numerica\n",
    "# Ahora procedemos a crear un Árbol de clasificación\n",
    "\n",
    "X$attack_category <- y_train\n",
    "#str(X)\n",
    "set.seed(1234)\n",
    "ind <- sample(2, nrow(X), replace=TRUE, prob=c(0.7, 0.3))\n",
    "Xr <- X[ind==1,]\n",
    "yr <- Xr$attack_category\n",
    "Xt <- X[ind==2,]\n",
    "yt <- Xt$attack_category\n",
    "rm(ind)\n",
    "\n",
    "# Ajustamos o creamos el árbol con la librería rpart\n",
    "fit <- rpart(Xr$attack_category~. , data=Xr, method=\"class\") # method=\"anova\" para regresión\n",
    "printcp(fit) # visualizar los resultados\n",
    "plotcp(fit) # visualizar los resultados de la validación cruzada\n",
    "summary(fit) # resumen detallado de los nodos\n",
    "\n",
    "# Gráficar el árbol\n",
    "plot(fit, uniform=TRUE, main=\"Arbol de Clasificacion de \\nTipos de Ataques en Redes\")\n",
    "text(fit, use.n=TRUE, all=TRUE, cex=.8)\n",
    "# Creamos un archivo postscript con el gráfico\n",
    "# post(fit, file = \"data/tree.ps\", title = \"Classification Tree for Attack types\")\n",
    "\n",
    "# Otra forma de visualizarlo\n",
    "rparty.tree <- as.party(fit)\n",
    "rparty.tree\n",
    "plot(rparty.tree)\n",
    "\n",
    "# Validación con los datos de prueba con duplicados\n",
    "# Esta validación es con el fin de poder comparar con la matríz de confusión del ganador\n",
    "X_test <- data_10_percent_test[,predictores]\n",
    "table(predict(tree.intrusos2, X_test), X_test$attack_category)\n",
    "# Precisión\n",
    "# ((203047 + 60378 + 2033 + 188 + 18) / 311029) * 100\n",
    "((201892 + 60377 + 2033 + 188 + 18) / 311029) * 100\n",
    "\n",
    "# table(predict(rparty.tree, X_test), X_test$attack_category)\n",
    "# ((59011 + 60355 + 1655 + 0 + 0) / 311029) * 100\n",
    "\n",
    "# Como se observa la precisión fue de 85.% comparada con la del ganador de 92.7%\n",
    "\n",
    "# predicted     0      1      2      3      4     %correct\n",
    "# actual       --------------------------------------------------\n",
    "#   0         |   60262    243     78      4      6       99.5%\n",
    "#   1         |     511   3471    184      0      0       83.3%\n",
    "#   2         |    5299   1328 223226      0      0       97.1%\n",
    "#   3         |     168     20      0     30     10       13.2%\n",
    "#   4         |   14527    294      0      8   1360        8.4%\n",
    "#   \n",
    "\n",
    "# Ahora probamos con otros algoritmos y metodos como random forest, bagging and boosting, KNN, etc.\n",
    "\n",
    "# Random Forest\n",
    "# system.time(Mod1 <- train(Xr$attack_category ~ ., method = \"rf\",\n",
    "#                data = Xr, importance = T, verbose=T, keep.forest=TRUE,\n",
    "#                trControl = trainControl(method = \"cv\", number = 3)))\n",
    "# save(Mod1,file=\"data/Mod1.RData\")\n",
    "# \n",
    "# load(\"data/Mod1.RData\")\n",
    "# # Mod1$finalModel\n",
    "# vi <- varImp(Mod1)\n",
    "# vi$importance[1:10,]\n",
    "# \n",
    "# # out-of-sample errors of random forest model using validation dataset \n",
    "# pred1 <- predict(Mod1, X_test) # type=\"class\"\n",
    "# cm1 <- confusionMatrix(pred1, X_test$attack_category)\n",
    "# cm1$table\n",
    "\n",
    "# Aplicamos Random Forest\n",
    "# En cualquiera de los casos crash RStudio, es necesario investigar el porque... parece ser por que son datos de texto o como factor la variable independiente\n",
    "# Como alternativa se utiliza ranger\n",
    "# Xr$attack_category<-yr\n",
    "# ?randomForest\n",
    "# str(Xr)\n",
    "# ataques_rf <- randomForest(Xr[1:40], Xr$attack_category, ntree=5, mtry=4, do.trace=T, \n",
    "#                            proximity=TRUE, importance=T)\n",
    "\n",
    "# ataques_rf <- randomForest(formula=Xr$attack_category~., Xr, ntree=10,\n",
    "#                            proximity=TRUE, importance=T, do.trace=T, keep.forest=T)\n",
    "# table(predict(ataques_rf, type=\"class\"),Xr$attack_category)\n",
    "\n",
    "# ----------\n",
    "# Random Forest utilizando la librería ranger\n",
    "# ----------\n",
    "# ?ranger\n",
    "ataques_rf <- ranger(formula=Xr$attack_category~.,data=Xr, num.trees=1000,  \n",
    "                     splitrule=\"gini\", verbose=TRUE ) # classification=TRUE, mtry = 4, min.node.size=1,\n",
    "\n",
    "ataques_rf$confusion.matrix\n",
    "# Validamos con el datset de prueba completo\n",
    "pred_rg <- predict(ataques_rf,X_test, type=\"response\")\n",
    "# summary(pred_rg)\n",
    "table(y_test, pred_rg$predictions)\n",
    "# Precisión\n",
    "(223279 + 60304 + 2369 + 952 + 0)/ length(y_test) * 100\n",
    "\n",
    "\n",
    "# Aplicamos Random Forest con Bagging\n",
    "# En este ejemplo si funciona por que hemos reemplazado la variable categárica\n",
    "set.seed(1)\n",
    "Xr$attack_category <- as.integer(as.factor(yr))\n",
    "# str(Xr)\n",
    "# system.time(bag.intrusos <- randomForest(Xr$attack_category~.,data=Xr,mtry=13,\n",
    "#                                          importance=TRUE, ntree=100, do.trace=T))\n",
    "# save(bag.intrusos,file=\"data/Mbag_intrusos.RData\")\n",
    "load(\"data/Mbag_intrusos.RData\")\n",
    "bag.intrusos\n",
    "#Xt$attack_category <- NULL\n",
    "predictions <- predict(bag.intrusos, Xt, type = \"response\")\n",
    "# mean((predictions-Xt)^2)\n",
    "importance(bag.intrusos) # Importancia de los predictores\n",
    "par(mfrow=c(1,1))\n",
    "varImpPlot(bag.intrusos)\n",
    "\n",
    "#table(yt, as.integer(predictions))\n",
    "\n",
    "yt_pred <- predict(bag.intrusos, X_test, type = \"response\")\n",
    "# mean((yt_pred - as.integer(X_test$attack_category))^2)\n",
    "# table(y_test, as.integer(yt_pred)) # Es necesario revisar el orden\n",
    "# # Precisión\n",
    "# (56146 + 210 + 944 + 926 + 5) / length(y_test)\n",
    "\n",
    "\n",
    "# Otra forma de hacerlo utilizando validación cruzada y la libreria \"caret\"\n",
    "# Pero esto toma demasiado tiempo por lo que queda comentado\n",
    "# Xr$attack_category <- factor(as.factor(yr)) #drop levels\n",
    "# model_rf  <- train(Xr$attack_category~., tuneLength = 3, data = Xr, \n",
    "#                    method=\"rf\", importance = TRUE,\n",
    "#                    trControl = trainControl(method = \"cv\",\n",
    "#                                             number = 5,\n",
    "#                                             savePredictions = \"final\",\n",
    "#                                             classProbs = T))\n",
    "# # Predicciones\n",
    "# model_rf$pred\n",
    "# model_rf$pred[order(model_rf$pred$rowIndex),2] # Ordenar como en los datos originales\n",
    "# # Matríz de confusion\n",
    "# confusionMatrix(model_rf$pred[order(model_rf$pred$rowIndex),2], Xr$attack_category)\n",
    "\n",
    "# Otra forma de hacerlo\n",
    "# set.seed(415)\n",
    "# Xr$attack_category <- as.factor(yr)\n",
    "# fitRF <- cforest(Xr$attack_category ~ ., data = Xr,  ntree=100, mtry=5) # controls=cforest_unbiased\n",
    "# predictionRF <- predict(fitRF, Xt, OOB=TRUE, type = \"response\")\n",
    "# predictionRF\n",
    "\n",
    "# --------------------------\n",
    "# Usamos la libreria \"e1071\" para utilizar el método 'tune' que \n",
    "# permite obtener los mejores parametros o mejor modelo a utilizar\n",
    "# Esta comentado por que toma mucho tiempo\n",
    "# Xr$attack_category <- as.factor(yr)\n",
    "# Xt$attack_category <- as.factor(yt)\n",
    "# tuned.r <- tune(randomForest, train.x = Xr$attack_category ~ ., data = Xr, validation.x = Xt$attack_category)\n",
    "# best.model <- tuned.r$best.model\n",
    "# predictions <- predict(best.model, Xt)\n",
    "# table.random.forest <- table(Xt$attack_category, predictions)\n",
    "# table.random.forest\n",
    "# # Computamos el error:\n",
    "# error.rate <- 1 - sum(diag(as.matrix(table.random.forest))) / sum(table.random.forest)\n",
    "# error.rate\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "# Boosting\n",
    "set.seed(12345)\n",
    "Xr$attack_category <- yr # factor(yr) # as.character()\n",
    "Xt$attack_category <- yt # factor(yt)\n",
    "boost.ataques4 <- gbm(Xr$attack_category~.,data=Xr,distribution=\"multinomial\", \n",
    "                      n.trees=50,interaction.depth=4, verbose=T)\n",
    "\n",
    "summary(boost.ataques4)\n",
    "boost.ataques4$num.classes\n",
    "y_pred4=predict.gbm(boost.ataques4,Xt,n.trees=50, type = \"response\")\n",
    "\n",
    "y_pred4[1:10,,]\n",
    "p.y_pred4 <- apply(y_pred4, 1, which.max)\n",
    "head(p.y_pred4)\n",
    "p.yp4_class <- colnames(y_pred4)[p.y_pred4]\n",
    "table(yt, p.yp4_class)\n",
    "# Precisión sobre el Xt\n",
    "# (15923 + 26275 + 224 + 87 + 0) / length(yt)\n",
    "\n",
    "# Validamos con los datos de prueba completos\n",
    "y_pred_4a=predict.gbm(boost.ataques4,X_test,n.trees=50, type = \"response\")\n",
    "# prob_pred4a = as.matrix(y_pred_4a[,,1])\n",
    "p.y_pred_4a <- apply(y_pred_4a, 1, which.max)\n",
    "p.y_pred_4a_class <- colnames(y_pred_4a)[p.y_pred_4a]\n",
    "table(y_test, p.y_pred_4a_class)\n",
    "# Precisión\n",
    "# (58996 + 60381 + 1574 + 35 + 0) / length(y_test)\n",
    "\n",
    "# Otra forma\n",
    "# boost.ataques6 <- gbm.fit(x=Xr[1:40], y=Xr$attack_category,distribution=\"multinomial\", \n",
    "#                       n.trees=50,interaction.depth=4, verbose=T)\n",
    "# \n",
    "# summary(boost.ataques6)\n",
    "# # Validamos con los datos de prueba completos\n",
    "# y_pred_6=predict.gbm(boost.ataques6,X_test[1:40],n.trees=50, type = \"response\")\n",
    "# # prob_pred6 = as.matrix(y_pred_6[,,1])\n",
    "# p.y_pred_6 <- apply(y_pred_6, 1, which.max)\n",
    "# p.y_pred_6_class <- colnames(y_pred_6)[p.y_pred_6]\n",
    "# table(y_test, p.y_pred_6_class)\n",
    "# # Precisión\n",
    "# (58994 + 60387 + 1571 + 35 + 0) / length(y_test)\n",
    "\n",
    "\n",
    "\n",
    "# Otra forma de hacerlo usando ambos bagging and boosting pero toma demasiado tiempo procesar; para revisar luego...\n",
    "# set.seed(123)\n",
    "# fitControl = trainControl(method=\"cv\", number=5) #returnResamp = \"all\"\n",
    "# # method = \"C5.0\", metric = \"kappa\"\n",
    "# Xr <- as.data.frame(Xr)\n",
    "# model2 = train(factor(Xr$attack_category)~.,data=Xr, method=\"gbm\",distribution=\"gaussian\", \n",
    "#                trControl=fitControl, verbose=T, \n",
    "#                tuneGrid=data.frame(.n.trees=50, .shrinkage=0.01, \n",
    "#                                    .interaction.depth=1, .n.minobsinnode=1))\n",
    "# \n",
    "# model2\n",
    "# confusionMatrix(model2)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 10. Resumen de los métodos utilizados\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# De acuerdo a los modelos ejecutados anteriormente, y sin ser muy rigurosos o meticulosos\n",
    "# en la elecciones de los mejores parametros o utilizando el conjunto de datos completos de 4 millones de registros\n",
    "# Podemos concluir que el mejor podria ser para esta solución 1, el de random forest bagging and boosting\n",
    "# utilizando la libreria ranger que fue la mas eficiente.\n",
    "# Aqui va una tabla y/o gráfico con la comparación de los resultados de todos los modelos. \n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 11. Comparación de resultados con el ganador del KDDCup\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Matríz de confusión de nuestros mejores resultados:\n",
    "#            dos normal  probe    r2l    u2r\n",
    "# dos     223279     12      7      0      0\n",
    "# normal      69  60304    216      2      2\n",
    "# probe        3      5   2369      0      0\n",
    "# r2l          0   5040      0    952      1\n",
    "# u2r          0     34      0      5      0\n",
    "\n",
    "# Precisión (223279 + 60304 + 2369 + 952 + 0)/ length(y_test) === 0.9224349\n",
    "\n",
    "\n",
    "# Matríz de confusión del ganador del concurso del KDD Cup 1999\n",
    "# predicted     0      1      2      3      4     %correct\n",
    "# actual       --------------------------------------------------\n",
    "#   0         |   60262    243     78      4      6       99.5%\n",
    "#   1         |     511   3471    184      0      0       83.3%\n",
    "#   2         |    5299   1328 223226      0      0       97.1%\n",
    "#   3         |     168     20      0     30     10       13.2%\n",
    "#   4         |   14527    294      0      8   1360        8.4%\n",
    "#   \n",
    "\n",
    "# Precisión === 0.9270808\n",
    "(60262 + 3471 + 223226 + 30 + 1360)/ length(y_test) * 100  \n",
    "\n",
    "\n",
    "# Queda mucho por explorar y realizar para mejorar la precisión, pero esto es solo un ejemplo\n",
    "# de como puede abordar un problema de este tipo en R.\n",
    "\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
